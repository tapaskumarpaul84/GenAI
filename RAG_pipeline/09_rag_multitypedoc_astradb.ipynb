{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72e11818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24678426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader=DirectoryLoader(path='F:\\\\Tapas\\\\Learning\\\\GenAI\\\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d40cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\miniconda3\\envs\\genai_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "Warning: No languages specified, defaulting to English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "doc=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb431dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter=RecursiveCharacterTextSplitter(chunk_size=512,chunk_overlap=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16b691e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'F:\\\\Tapas\\\\Learning\\\\GenAI\\\\data\\\\2501.09136v3.pdf'}, page_content='5 2 0 2\\n\\nb e F 4\\n\\n] I\\n\\nA . s c [\\n\\n3 v 6 3 1 9 0 . 1 0 5 2 : v i X r a\\n\\nAGENTIC RETRIEVAL-AUGMENTED GENERATION: A SURVEY ON AGENTIC RAG\\n\\nAditi Singh Department of Computer Science Cleveland State University Cleveland, OH, USA a.singh22@csuohio.edu\\n\\nAbul Ehtesham The Davey Tree Expert Company Kent, OH, USA abul.ehtesham@davey.com\\n\\nSaket Kumar The MathWorks Inc Natick, MA, USA saketk@mathworks.com\\n\\nTala Talaei Khoei Khoury College of Computer Science Roux Institute at Northeastern University Portland, ME, USA t.talaeikhoei@northeastern.edu\\n\\nABSTRACT\\n\\nLarge Language Models (LLMs) have revolutionized artificial intelligence (AI) by enabling human- like text generation and natural language understanding. However, their reliance on static training data limits their ability to respond to dynamic, real-time queries, resulting in outdated or inaccurate outputs. Retrieval-Augmented Generation (RAG) has emerged as a solution, enhancing LLMs by integrating real-time data retrieval to provide contextually relevant and up-to-date responses. Despite its promise, traditional RAG systems are constrained by static workflows and lack the adaptability required for multi-step reasoning and complex task management.\\n\\nAgentic Retrieval-Augmented Generation (Agentic RAG) transcends these limitations by embedding autonomous AI agents into the RAG pipeline. These agents leverage agentic design patterns reflec- tion, planning, tool use, and multi-agent collaboration to dynamically manage retrieval strategies, iteratively refine contextual understanding, and adapt workflows through clearly defined operational structures ranging from sequential steps to adaptive collaboration. This integration enables Agentic RAG systems to deliver unparalleled flexibility, scalability, and context-awareness across diverse applications.\\n\\nThis survey provides a comprehensive exploration of Agentic RAG, beginning with its foundational principles and the evolution of RAG paradigms. It presents a detailed taxonomy of Agentic RAG archi- tectures, highlights key applications in industries such as healthcare, finance, and education, and exam- ines practical implementation strategies. Additionally, it addresses challenges in scaling these systems, ensuring ethical decision-making, and optimizing performance for real-world applications, while providing detailed insights into frameworks and tools for implementing Agentic RAG 1. The GitHub link for this survey is available at: https://github.com/asinghcsu/AgenticRAG-Survey.\\n\\nKeywords Large Language Models (LLMs) · Artificial Intelligence (AI) · Natural Language Understanding · Retrieval-Augmented Generation (RAG) · Agentic RAG · Autonomous AI Agents · Reflection · Planning · Tool Use · Multi-Agent Collaboration · Agentic Patterns · Contextual Understanding · Dynamic Adaptability · Scalability · Real-Time Data Retrieval · Taxonomy of Agentic RAG · Healthcare Applications · Finance Applications · Educational Applications · Ethical AI Decision-Making · Performance Optimization · Multi-Step Reasoning\\n\\n1GitHub link: https://github.com/asinghcsu/AgenticRAG-Survey\\n\\n1 Introduction\\n\\nLarge Language Models (LLMs) [1, 2] [3], such as OpenAI’s GPT-4, Google’s PaLM, and Meta’s LLaMA, have signifi- cantly transformed artificial intelligence (AI) with their ability to generate human-like text and perform complex natural language processing tasks. These models have driven innovation across diverse domains, including conversational agents [4], automated content creation, and real-time translation. Recent advancements have extended their capabilities to multimodal tasks, such as text-to-image and text-to-video generation [5], enabling the creation and editing of videos and images from detailed prompts [6], which broadens the potential applications of generative AI.\\n\\nDespite these advancements, LLMs face significant limitations due to their reliance on static pre-training data. This reliance often results in outdated information, hallucinated responses [7], and an inability to adapt to dynamic, real-world scenarios. These challenges emphasize the need for systems that can integrate real-time data and dynamically refine responses to maintain contextual relevance and accuracy.\\n\\nRetrieval-Augmented Generation (RAG) [8, 9] emerged as a promising solution to these challenges. By combining the generative capabilities of LLMs with external retrieval mechanisms [10], RAG systems enhance the relevance and timeliness of responses. These systems retrieve real-time information from sources such as knowledge bases [11], APIs, or the web, effectively bridging the gap between static training data and the demands of dynamic applications. However, traditional RAG workflows remain limited by their linear and static design, which restricts their ability to perform complex multi-step reasoning, integrate deep contextual understanding, and iteratively refine responses.\\n\\nThe evolution of agents [12] has significantly enhanced the capabilities of AI systems. Modern agents, including LLM-powered and mobile agents [13], are intelligent entities capable of perceiving, reasoning, and autonomously executing tasks. These agents leverage agentic patterns, such as reflection [14], planning [15], tool use, and multi-agent collaboration [16], to enhance decision-making and adaptability.\\n\\nFurthermore, these agents employ agentic workflow patterns [12, 13], such as prompt chaining, routing, parallelization, orchestrator-worker models, and evaluator-optimizer , to structure and optimize task execution. By integrating these patterns, Agentic RAG systems can efficiently manage dynamic workflows and address complex problem-solving scenarios. The convergence of RAG and agentic intelligence has given rise to Agentic Retrieval-Augmented Generation (Agentic RAG) [14], a paradigm that integrates agents into the RAG pipeline. Agentic RAG enables dynamic retrieval strategies, contextual understanding, and iterative refinement [15], allowing for adaptive and efficient information processing. Unlike traditional RAG, Agentic RAG employs autonomous agents to orchestrate retrieval, filter relevant information, and refine responses, excelling in scenarios requiring precision and adaptability. The overview of Agentic RAG is in figure 1.\\n\\nThis survey explores the foundational principles, taxonomy, and applications of Agentic RAG. It provides a comprehen- sive overview of RAG paradigms, such as Naïve RAG, Modular RAG, and Graph RAG [16], alongside their evolution into Agentic RAG systems. Key contributions include a detailed taxonomy of Agentic RAG frameworks, applications across domains such as healthcare [17, 18], finance, and education [19], and insights into implementation strategies, benchmarks, and ethical considerations.\\n\\nThe structure of this paper is as follows: Section 2 introduces RAG and its evolution, highlighting the limitations of traditional approaches. Section 3 elaborates on the principles of agentic intelligence and agentic patterns. Section 4 elaborates agentic workflow patterns. Section 5 provides a taxonomy of Agentic RAG systems, including single-agent, multi-agent, and graph-based frameworks. Section 6 provides comparative analysis of Agentic RAG frameworks. Section 7 examines applications of Agentic RAG, while Section 8 discusses implementation tools and frameworks. Section 9 focuses on benchmarks and dataset, and Section 10 concludes with future directions for Agentic RAG systems.\\n\\n2 Foundations of Retrieval-Augmented Generation\\n\\n2.1 Overview of Retrieval-Augmented Generation (RAG)\\n\\nRetrieval-Augmented Generation (RAG) represents a significant advancement in the field of artificial intelligence, combining the generative capabilities of Large Language Models (LLMs) with real-time data retrieval. While LLMs have demonstrated remarkable capabilities in natural language processing, their reliance on static pre-trained data often results in outdated or incomplete responses. RAG addresses this limitation by dynamically retrieving relevant information from external sources and incorporating it into the generative process, enabling contextually accurate and up-to-date outputs.\\n\\n2\\n\\nFigure 1: An Overview of Agentic RAG\\n\\n2.2 Core Components of RAG\\n\\nThe architecture of RAG systems integrates three primary components (Figure2):\\n\\nRetrieveal: Responsible for querying external data sources such as knowledge bases, APIs, or vector databases. Advanced retrievers leverage dense vector search and transformer-based models to improve retrieval precision and semantic relevance.\\n\\nAugmentation: Processes retrieved data, extracting and summarizing the most relevant information to align with the query context.\\n\\nGeneration: Combines retrieved information with the LLM’s pre-trained knowledge to generate coherent, contextually appropriate responses.\\n\\n2.3 Evolution of RAG Paradigms\\n\\nThe field of Retrieval-Augmented Generation (RAG) has evolved significantly to address the increasing complexity of real-world applications, where contextual accuracy, scalability, and multi-step reasoning are critical. What began as simple keyword-based retrieval has transitioned into sophisticated, modular, and adaptive systems capable of integrating diverse data sources and autonomous decision-making processes. This evolution underscores the growing need for RAG systems to handle complex queries efficiently and effectively.\\n\\nThis section examines the progression of RAG paradigms, presenting key stages of development—Naïve RAG, Advanced RAG, Modular RAG, Graph RAG, and Agentic RAG alongside their defining characteristics, strengths, and\\n\\n3\\n\\nFigure 2: Core Components of RAG\\n\\nlimitations. By understanding the evolution of these paradigms, readers can appreciate the advancements made in retrieval and generative capabilities and their application in various domains\\n\\n2.3.1 Naïve RAG\\n\\nNaïve RAG [20] represents the foundational implementation of retrieval-augmented generation. Figure 3 illustrates the simple retrieve-read workflow of Naive RAG, focusing on keyword-based retrieval and static datasets.. These systems rely on simple keyword-based retrieval techniques, such as TF-IDF and BM25, to fetch documents from static datasets. The retrieved documents are then used to augment the language model’s generative capabilities.\\n\\nFigure 3: An Overview of Naive RAG.\\n\\nNaïve RAG is characterized by its simplicity and ease of implementation, making it suitable for tasks involving fact-based queries with minimal contextual complexity. However, it suffers from several limitations:\\n\\nLack of Contextual Awareness: Retrieved documents often fail to capture the semantic nuances of the query due to reliance on lexical matching rather than semantic understanding.\\n\\nFragmented Outputs: The absence of advanced preprocessing or contextual integration often leads to disjointed or overly generic responses.\\n\\nScalability Issues: Keyword-based retrieval techniques struggle with large datasets, often failing to identify the most relevant information.\\n\\nDespite these limitations, Naïve RAG systems provided a critical proof-of-concept for integrating retrieval with generation, laying the foundation for more sophisticated paradigms.\\n\\n2.3.2 Advanced RAG\\n\\nAdvanced RAG [20] systems build upon the limitations of Naïve RAG by incorporating semantic understanding and enhanced retrieval techniques. Figure 4 highlights the semantic enhancements in retrieval and the iterative, context- aware pipeline of Advanced RAG. These systems leverage dense retrieval models, such as Dense Passage Retrieval (DPR), and neural ranking algorithms to improve retrieval precision.\\n\\nKey features of Advanced RAG include:\\n\\n4\\n\\nFigure 4: Overview of Advanced RAG\\n\\nDense Vector Search: Queries and documents are represented in high-dimensional vector spaces, enabling better semantic alignment between the user query and retrieved documents.\\n\\nContextual Re-Ranking: Neural models re-rank retrieved documents to prioritize the most contextually relevant information.\\n\\nIterative Retrieval: Advanced RAG introduces multi-hop retrieval mechanisms, enabling reasoning across multiple documents for complex queries.\\n\\nThese advancements make Advanced RAG suitable for applications requiring high precision and nuanced understanding, such as research synthesis and personalized recommendations. However, challenges such as computational overhead and limited scalability persist, particularly when dealing with large datasets or multi-step queries.\\n\\n2.3.3 Modular RAG\\n\\nModular RAG [20] represents the latest evolution in RAG paradigms, emphasizing flexibility and customization. These systems decompose the retrieval and generation pipeline into independent, reusable components, enabling domain-specific optimization and task adaptability. Figure 5 demonstrates the modular architecture, showcasing hybrid retrieval strategies, composable pipelines, and external tool integration.\\n\\nKey innovations in Modular RAG include:\\n\\nHybrid Retrieval Strategies: Combining sparse retrieval methods (e.g., a sparse encoder-BM25) with dense retrieval techniques [21] (e.g., DPR - Dense Passage Retrieval ) to maximize accuracy across diverse query types.\\n\\nTool Integration: Incorporating external APIs, databases, or computational tools to handle specialized tasks, such as real-time data analysis or domain-specific computations.\\n\\nComposable Pipelines: Modular RAG enables retrievers, generators, and other components to be replaced, enhanced, or reconfigured independently, allowing high adaptability to specific use cases.\\n\\nFor instance, a Modular RAG system designed for financial analytics might retrieve live stock prices via APIs, analyze historical trends using dense retrieval, and generate actionable investment insights through a tailored language model. This modularity and customization make Modular RAG ideal for complex, multi-domain tasks, offering both scalability and precision.\\n\\n5\\n\\nFigure 5: Overview of Modular RAG\\n\\n2.3.4 Graph RAG\\n\\nGraph RAG [16] extends traditional Retrieval-Augmented Generation systems by integrating graph-based data structures as illustrated in Figure 6. These systems leverage the relationships and hierarchies within graph data to enhance multi- hop reasoning and contextual enrichment. By incorporating graph-based retrieval, Graph RAG enables richer and more accurate generative outputs, particularly for tasks requiring relational understanding.\\n\\nGraph RAG is characterized by its ability to:\\n\\nNode Connectivity: Captures and reasons over relationships between entities.\\n\\nHierarchical Knowledge Management: Handles structured and unstructured data through graph-based hierarchies.\\n\\nContext Enrichment: Adds relational understanding by leveraging graph-based pathways.\\n\\nHowever, Graph RAG has some limitations:\\n\\nLimited Scalability: The reliance on graph structures can restrict scalability, especially with extensive data sources.\\n\\nData Dependency: High-quality graph data is essential for meaningful outputs, limiting its applicability in unstructured or poorly annotated datasets.\\n\\nComplexity of Integration: Integrating graph data with unstructured retrieval systems increases design and implementation complexity.\\n\\nGraph RAG is well-suited for applications such as healthcare diagnostics, legal research, and other domains where reasoning over structured relationships is crucial.\\n\\n2.3.5 Agentic RAG\\n\\nAgentic RAG represents a paradigm shift by introducing autonomous agents capable of dynamic decision-making and workflow optimization. Unlike static systems, Agentic RAG employs iterative refinement and adaptive retrieval strategies to address complex, real-time, and multi-domain queries. This paradigm leverages the modularity of retrieval and generation processes while introducing agent-based autonomy.\\n\\n6\\n\\nFigure 6: Overview of Graph RAG\\n\\nKey characteristics of Agentic RAG include:\\n\\nAutonomous Decision-Making: Agents independently evaluate and manage retrieval strategies based on query complexity.\\n\\nIterative Refinement: Incorporates feedback loops to improve retrieval accuracy and response relevance.\\n\\nWorkflow Optimization: Dynamically orchestrates tasks, enabling efficiency in real-time applications.\\n\\nDespite its advancements, Agentic RAG faces some challenges:\\n\\nCoordination Complexity: Managing interactions between agents requires sophisticated orchestration mechanisms.\\n\\nComputational Overhead: The use of multiple agents increases resource requirements for complex work- flows.\\n\\nScalability Limitations: While scalable, the dynamic nature of the system can strain computational resources for high query volumes.\\n\\nAgentic RAG excels in domains like customer support, financial analytics, and adaptive learning platforms, where dynamic adaptability and contextual precision are paramount.\\n\\n2.4 Challenges and Limitations of Traditional RAG Systems\\n\\nTraditional Retrieval-Augmented Generation (RAG) systems have significantly expanded the capabilities of Large Language Models (LLMs) by integrating real-time data retrieval. However, these systems still face critical challenges that hinder their effectiveness in complex, real-world applications. The most notable limitations revolve around contextual integration, multi-step reasoning, and scalability and latency issues.\\n\\n2.4.1 Contextual Integration\\n\\nEven when RAG systems successfully retrieve relevant information, they often struggle to seamlessly incorporate it into generated responses. The static nature of retrieval pipelines and limited contextual awareness lead to fragmented, inconsistent, or overly generic outputs.\\n\\nExample: A query such as, \"What are the latest advancements in Alzheimer’s research and their implications for early-stage treatment?\" might yield relevant research papers and medical guidelines. However, traditional RAG systems often fail to synthesize these findings into a coherent explanation that connects the new treatments to specific patient scenarios. Similarly, for a query like, \"What are the best sustainable practices for small-scale agriculture in arid regions?\", traditional systems might retrieve documents on general agricultural methods but overlook critical sustainability practices tailored to arid environments.\\n\\n7\\n\\nTable 1: Comparative Analysis of RAG Paradigms\\n\\nParadigm\\n\\nKey Features\\n\\nStrengths\\n\\nNaïve RAG\\n\\nKeyword-based retrieval (e.g., TF-IDF, BM25)\\n\\nSimple and easy to implement • Suitable for fact-based queries\\n\\nAdvanced RAG\\n\\nDense retrieval models (e.g., DPR)\\n\\nNeural ranking and re-ranking • Multi-hop retrieval\\n\\nHigh precision retrieval • Improved contextual relevance\\n\\nModular RAG\\n\\nHybrid retrieval (sparse and dense)\\n\\nTool and API integration • Composable, domain-specific pipelines\\n\\nHigh flexibility and customization • Suitable for diverse applications • Scalable\\n\\nGraph RAG\\n\\nIntegration of graph-based structures\\n\\nMulti-hop reasoning • Contextual enrichment via nodes\\n\\nRelational reasoning capabilities • Mitigates hallucinations • Ideal for structured data tasks\\n\\nAgentic RAG\\n\\nAutonomous agents • Dynamic decision-making • Iterative refinement and work- flow optimization\\n\\nAdaptable to real-time changes • Scalable for multi-domain tasks • High accuracy\\n\\n2.4.2 Multi-Step Reasoning\\n\\nMany real-world queries require iterative or multi-hop reasoning—retrieving and synthesizing information across multiple steps. Traditional RAG systems are often ill-equipped to refine retrieval based on intermediate insights or user feedback, resulting in incomplete or disjointed responses.\\n\\nExample: A complex query like, \"What lessons from renewable energy policies in Europe can be applied to developing nations, and what are the potential economic impacts?\" demands the orchestration of multiple types of information, including policy data, contextualization for developing regions, and economic analysis. Traditional RAG systems typically fail to connect these disparate elements into a cohesive response.\\n\\n2.4.3 Scalability and Latency Issues\\n\\nAs the volume of external data sources grows, querying and ranking large datasets becomes increasingly computationally intensive. This results in significant latency, which undermines the system’s ability to provide timely responses in real-time applications.\\n\\nExample: In time-sensitive settings such as financial analytics or live customer support, delays caused by querying multiple databases or processing large document sets can hinder the system’s overall utility. For example, a delay in retrieving market trends during high-frequency trading could result in missed opportunities.\\n\\n2.5 Agentic RAG: A Paradigm Shift\\n\\nTraditional RAG systems, with their static workflows and limited adaptability, often struggle to handle dynamic, multi- step reasoning and complex real-world tasks. These limitations have spurred the integration of agentic intelligence,\\n\\n8\\n\\nresulting in Agentic RAG. By incorporating autonomous agents capable of dynamic decision-making, iterative reasoning, and adaptive retrieval strategies, Agentic RAG builds on the modularity of earlier paradigms while overcoming their inherent constraints. This evolution enables more complex, multi-domain tasks to be addressed with enhanced precision and contextual understanding, positioning Agentic RAG as a cornerstone for next-generation AI applications. In particular, Agentic RAG systems reduce latency through optimized workflows and refine outputs iteratively, tackling the very challenges that have historically hindered traditional RAG’s scalability and effectiveness.\\n\\n3 Core Principles and Background of Agentic Intelligence\\n\\nAgentic Intelligence forms the foundation of Agentic Retrieval-Augmented Generation (RAG) systems, enabling them to transcend the static and reactive nature of traditional RAG. By integrating autonomous agents capable of dynamic decision-making, iterative reasoning, and collaborative workflows, Agentic RAG systems exhibit enhanced adaptability and precision. This section explores the core principles underpinning agentic intelligence.\\n\\nComponents of an AI Agent.\\n\\nIn essence, an AI agent comprises (Figure. 7):\\n\\nLLM (with defined Role and Task): Serves as the agent’s primary reasoning engine and dialogue interface. It interprets user queries, generates responses, and maintains coherence.\\n\\nMemory (Short-Term and Long-Term): Captures context and relevant data across interactions. Short-term memory [22] tracks immediate conversation state, while long-term memory [22]stores accumulated knowledge and agent experiences.\\n\\nPlanning (Reflection & Self-Critique): Guides the agent’s iterative reasoning process through reflection, query routing, or self-critique[23], ensuring that complex tasks are broken down effectively [24].\\n\\nTools Vector Search, Web Search, APIs, etc.): Expands the agent’s capabilities beyond text generation, enabling access to external resources, real-time data, or specialized computations.\\n\\nFigure 7: An Overview of AI Agents\\n\\nAgentic Patterns [25, 26] provide structured methodologies that guide the behavior of agents in Agentic Retrieval- Augmented Generation (RAG) systems. These patterns enable agents to dynamically adapt, plan, and collaborate, ensuring that the system can handle complex, real-world tasks with precision and scalability. Four key patterns underpin agentic workflows:\\n\\n3.1 Reflection\\n\\nReflection is a foundational design pattern in agentic workflows, enabling agents to iteratively evaluate and refine their outputs. By incorporating self-feedback mechanisms, agents can identify and address errors, inconsistencies, and areas for improvement, enhancing performance across tasks like code generation, text production, and question answering (\\n\\n9\\n\\nas shown in Figure 8). In practical use, Reflection involves prompting an agent to critique its outputs for correctness, style, and efficiency, then incorporating this feedback into subsequent iterations. External tools, such as unit tests or web searches, can further enhance this process by validating results and highlighting gaps.\\n\\nIn multi-agent systems, Reflection can involve distinct roles, such as one agent generating outputs while another critiques them, fostering collaborative improvement. For instance, in legal research, agents can iteratively refine responses by re-evaluating retrieved case law, ensuring accuracy and comprehensiveness. Reflection has demonstrated significant performance improvements in studies like Self-Refine [27], Reflexion [28], and CRITIC [23].\\n\\nFigure 8: An Overview of Agentic Self- Reflection\\n\\n3.2 Planning\\n\\nPlanning [24] is a key design pattern in agentic workflows that enables agents to autonomously decompose complex tasks into smaller, manageable subtasks. This capability is essential for multi-hop reasoning and iterative problem-solving in dynamic and uncertain scenarios as shown in Figure 9a.\\n\\nBy leveraging planning, agents can dynamically determine the sequence of steps needed to accomplish a larger objective. This adaptability allows agents to handle tasks that cannot be predefined, ensuring flexibility in decision-making. While powerful, Planning can produce less predictable outcomes compared to deterministic workflows like Reflection. Planning is particularly suited for tasks that require dynamic adaptation, where predefined workflows are insufficient. As the technology matures, its potential to drive innovative applications across domains will continue to grow.\\n\\n3.3 Tool Use\\n\\nTool Use enables agents to extend their capabilities by interacting with external tools, APIs, or computational resources as illustrated in 9b. This pattern allows agents to gather information, perform computations, and manipulate data beyond their pre-trained knowledge. By dynamically integrating tools into workflows, agents can adapt to complex tasks and provide more accurate and contextually relevant outputs.\\n\\nModern agentic workflows incorporate tool use for a variety of applications, including information retrieval, computa- tional reasoning, and interfacing with external systems. The implementation of this pattern has evolved significantly with advancements like GPT-4’s function calling capabilities and systems capable of managing access to numerous tools. These developments facilitate sophisticated workflows where agents autonomously select and execute the most relevant tools for a given task.\\n\\nWhile tool use significantly enhances agentic workflows, challenges remain in optimizing the selection of tools, particularly in contexts with a large number of available options. Techniques inspired by retrieval-augmented generation (RAG), such as heuristic-based selection, have been proposed to address this issue.\\n\\n3.4 Multi-Agent\\n\\nMulti-agent collaboration [29] is a key design pattern in agentic workflows that enables task specialization and parallel processing. Agents communicate and share intermediate results, ensuring the overall workflow remains efficient and coherent. By distributing subtasks among specialized agents, this pattern improves the scalability and adaptability\\n\\n10\\n\\n(a) An Overview of Agentic Planning\\n\\n(b) An Overview of Tool Use\\n\\nFigure 9: Overview of Agentic Planning and Tool Use\\n\\nof complex workflows. Multi-agent systems allow developers to decompose intricate tasks into smaller, manageable subtasks assigned to different agents. This approach not only enhances task performance but also provides a robust framework for managing complex interactions. Each agent operates with its own memory and workflow, which can include the use of tools, reflection, or planning, enabling dynamic and collaborative problem-solving (see Figure 10).\\n\\nWhile multi-agent collaboration offers significant potential, it is a less predictable design pattern compared to more mature workflows like Reflection and Tool Use. Nevertheless, emerging frameworks such as AutoGen, Crew AI, and LangGraph are providing new avenues for implementing effective multi-agent solutions.\\n\\nFigure 10: An Overview of MultiAgent\\n\\nThese design patterns form the foundation for the success of Agentic RAG systems. By structuring workflows—from simple, sequential steps to more adaptive, collaborative processes—these patterns enable systems to dynamically adapt their retrieval and generative strategies to the diverse and ever-changing demands of real-world environments. Leveraging these patterns, agents are capable of handling iterative, context-aware tasks that significantly exceed the capabilities of traditional RAG systems.\\n\\n4 Agentic Workflow Patterns: Adaptive Strategies for Dynamic Collaboration\\n\\nAgentic workflow patterns, [12, 13] structure LLM-based applications to optimize performance, accuracy, and efficiency. Different approaches are suitable depending on task complexity and processing requirements.\\n\\n11\\n\\n4.1 Prompt Chaining: Enhancing Accuracy Through Sequential Processing\\n\\nPrompt chaining [12, 13] decomposes a complex task into multiple steps, where each step builds upon the previous one. This structured approach improves accuracy by simplifying each subtask before moving forward. However, it may increase latency due to sequential processing.\\n\\nFigure 11: Illustration of Prompt Chaining Workflow\\n\\nWhen to Use: This workflow is most effective when a task can be broken down into fixed subtasks, each contributing to the final output. It is particularly useful in scenarios where step-by-step reasoning enhances accuracy.\\n\\nExample Applications:\\n\\nGenerating marketing content in one language and then translating it into another while preserving nuances. • Structuring document creation by first generating an outline, verifying its completeness, and then developing the full text.\\n\\n4.2 Routing:Directing Inputs to Specialized Processes\\n\\nRouting [12, 13] involves classifying an input and directing it to an appropriate specialized prompt or process. This method ensures distinct queries or tasks are handled separately, improving efficiency and response quality.\\n\\nFigure 12: Illustration Routing Workflow\\n\\nWhen to Use: Ideal for scenarios where different types of input require distinct handling strategies, ensuring optimized performance for each category.\\n\\nExample Applications:\\n\\nDirecting customer service queries into categories such as technical support, refund requests, or general inquiries.\\n\\n12\\n\\nAssigning simple queries to smaller models for cost efficiency, while complex requests go to advanced models.\\n\\n4.3 Parallelization: Speeding Up Processing Through Concurrent Execution\\n\\nParallelization [12, 13] divides a task into independent processes that run simultaneously, reducing latency and improving throughput. It can be categorized into sectioning (independent subtasks) and voting (multiple outputs for accuracy).\\n\\nFigure 13: Illustration of Parallelization Workflow\\n\\nWhen to Use: Useful when tasks can be executed independently to enhance speed or when multiple outputs improve confidence.\\n\\nExample Applications:\\n\\nSectioning: Splitting tasks like content moderation, where one model screens input while another generates a response.\\n\\nVoting: Using multiple models to cross-check code for vulnerabilities or analyze content moderation decisions.\\n\\n4.4 Orchestrator-Workers: Dynamic Task Delegation\\n\\nThis workflow [12, 13] features a central orchestrator model that dynamically breaks tasks into subtasks, assigns them to specialized worker models, and compiles the results. Unlike parallelization, it adapts to varying input complexity.\\n\\nFigure 14: Illustration of Orchestrator-Workers Workflow\\n\\nWhen to Use: Best suited for tasks requiring dynamic decomposition and real-time adaptation, where subtasks are not predefined.\\n\\n13\\n\\nExample Applications:\\n\\nAutomatically modifying multiple files in a codebase based on the nature of requested changes. • Conducting real-time research by gathering and synthesizing relevant information from multiple sources.\\n\\n4.5 Evaluator-Optimizer: Refining Output Through Iteration\\n\\nThe evaluator-optimizer [12, 13] workflow iteratively improves content by generating an initial output and refining it based on feedback from an evaluation model.\\n\\nFigure 15: Illustration of Evaluator-Optimizer Workflow\\n\\nWhen to Use: Effective when iterative refinement significantly enhances response quality, especially when clear evaluation criteria exist.\\n\\nExample Applications:\\n\\nImproving literary translations through multiple evaluation and refinement cycles. • Conducting multi-round research queries where additional iterations refine search results.\\n\\n5 Taxonomy of Agentic RAG Systems\\n\\nAgentic Retrieval-Augmented Generation (RAG) systems can be categorized into distinct architectural frameworks based on their complexity and design principles. These include single-agent architectures, multi-agent systems, and hi- erarchical agentic architectures. Each framework is tailored to address specific challenges and optimize performance for diverse applications. This section provides a detailed taxonomy of these architectures, highlighting their characteristics, strengths, and limitations.\\n\\n5.1 Single-Agent Agentic RAG: Router\\n\\nA Single-Agent Agentic RAG: [30] serves as a centralized decision-making system where a single agent manages the retrieval, routing, and integration of information (as shown in Figure. 16). This architecture simplifies the system by consolidating these tasks into one unified agent, making it particularly effective for setups with a limited number of tools or data sources.\\n\\nWorkflow\\n\\n1. Query Submission and Evaluation: The process begins when a user submits a query. A coordinating agent (or master retrieval agent) receives the query and analyzes it to determine the most suitable sources of information.\\n\\n2. Knowledge Source Selection: Based on the query’s type, the coordinating agent chooses from a variety of retrieval options:\\n\\n14\\n\\nStructured Databases: For queries requiring tabular data access, the system may use a Text-to-SQL engine that interacts with databases like PostgreSQL or MySQL.\\n\\nSemantic Search: When dealing with unstructured information, it retrieves relevant documents (e.g., PDFs, books, organizational records) using vector-based retrieval.\\n\\nWeb Search: For real-time or broad contextual information, the system leverages a web search tool to access the latest online data.\\n\\nRecommendation Systems: For personalized or contextual queries, the system taps into recommendation engines that provide tailored suggestions.\\n\\n3. Data Integration and LLM Synthesis: Once the relevant data is retrieved from the chosen sources, it is passed to a Large Language Model (LLM). The LLM synthesizes the gathered information, integrating insights from multiple sources into a coherent and contextually relevant response.\\n\\n4. Output Generation: Finally, the system delivers a comprehensive, user-facing answer that addresses the original query. This response is presented in an actionable, concise format and may optionally include references or citations to the sources used.\\n\\nFigure 16: An Overview of Single Agentic RAG\\n\\nKey Features and Advantages.\\n\\nCentralized Simplicity: A single agent handles all retrieval and routing tasks, making the architecture straightforward to design, implement, and maintain.\\n\\nEfficiency & Resource Optimization: With fewer agents and simpler coordination, the system demands fewer computational resources and can handle queries more quickly.\\n\\nDynamic Routing: The agent evaluates each query in real-time, selecting the most appropriate knowledge source (e.g., structured DB, semantic search, web search).\\n\\nVersatility Across Tools: Supports a variety of data sources and external APIs, enabling both structured and unstructured workflows.\\n\\nIdeal for Simpler Systems: Suited for applications with well-defined tasks or limited integration requirements (e.g., document retrieval, SQL-based workflows).\\n\\n15\\n\\nUse Case: Customer Support\\n\\nPrompt: Can you tell me the delivery status of my order?\\n\\nSystem Process (Single-Agent Workflow):\\n\\n1. Query Submission and Evaluation:\\n\\nThe user submits the query, which is received by the coordinating agent. • The coordinating agent analyzes the query and determines the most appropriate sources of information.\\n\\n2. Knowledge Source Selection:\\n\\nRetrieves tracking details from the order management database. • Fetches real-time updates from the shipping provider’s API. • Optionally conducts a web search to identify local conditions affecting delivery, such as weather or logistical delays.\\n\\n3. Data Integration and LLM Synthesis:\\n\\nThe relevant data is passed to the LLM, which synthesizes the information into a coherent\\n\\nresponse. 4. Output Generation:\\n\\nThe system generates an actionable and concise response, providing live tracking updates and potential alternatives.\\n\\nResponse: Integrated Response: “Your package is currently in transit and expected to arrive tomorrow evening. The live tracking from UPS indicates it is at the regional distribution center.”\\n\\n5.2 Multi-Agent Agentic RAG Systems:\\n\\nMulti-Agent RAG [30] represents a modular and scalable evolution of single-agent architectures, designed to handle complex workflows and diverse query types by leveraging multiple specialized agents (as shown in Figure 17). Instead of relying on a single agent to manage all tasks—reasoning, retrieval, and response generation—this system distributes responsibilities across multiple agents, each optimized for a specific role or data source.\\n\\nWorkflow\\n\\n1. Query Submission: The process begins with a user query, which is received by a coordinator agent or master retrieval agent. This agent acts as the central orchestrator, delegating the query to specialized retrieval agents based on the query’s requirements.\\n\\n2. Specialized Retrieval Agents: The query is distributed among multiple retrieval agents, each focusing on a specific type of data source or task. Examples include:\\n\\nAgent 1: Handles structured queries, such as interacting with SQL-based databases like PostgreSQL or MySQL.\\n\\nAgent 2: Manages semantic searches for retrieving unstructured data from sources like PDFs, books, or internal records.\\n\\nAgent 3: Focuses on retrieving real-time public information from web searches or APIs. • Agent 4: Specializes in recommendation systems, delivering context-aware suggestions based on user behavior or profiles.\\n\\n3. Tool Access and Data Retrieval: Each agent routes the query to the appropriate tools or data sources within its domain, such as:\\n\\nVector Search: For semantic relevance. • Text-to-SQL: For structured data. • Web Search: For real-time public information. • APIs: For accessing external services or proprietary systems.\\n\\nThe retrieval process is executed in parallel, allowing for efficient processing of diverse query types.\\n\\n16\\n\\nFigure 17: An Overview of Multi-Agent Agentic RAG Systems\\n\\n4. Data Integration and LLM Synthesis: Once retrieval is complete, the data from all agents is passed to a Large Language Model (LLM). The LLM synthesizes the retrieved information into a coherent and contextually relevant response, integrating insights from multiple sources seamlessly.\\n\\n5. Output Generation: The system generates a comprehensive response, which is delivered back to the user in an actionable and concise format.\\n\\nKey Features and Advantages.\\n\\nModularity: Each agent operates independently, allowing for seamless addition or removal of agents based on system requirements.\\n\\nScalability: Parallel processing by multiple agents enables the system to handle high query volumes efficiently.\\n\\nTask Specialization: Each agent is optimized for a specific type of query or data source, improving accuracy and retrieval relevance.\\n\\nEfficiency: By distributing tasks across specialized agents, the system minimizes bottlenecks and enhances performance for complex workflows.\\n\\nVersatility: Suitable for applications spanning multiple domains, including research, analytics, decision- making, and customer support.\\n\\nChallenges\\n\\nCoordination Complexity: Managing inter-agent communication and task delegation requires sophisticated orchestration mechanisms.\\n\\nComputational Overhead: Parallel processing of multiple agents can increase resource usage.\\n\\nData Integration: Synthesizing outputs from diverse sources into a cohesive response is non-trivial and requires advanced LLM capabilities.\\n\\n17\\n\\nUse Case: Multi-Domain Research Assistant\\n\\nPrompt: What are the economic and environmental impacts of renewable energy adoption in Europe?\\n\\nSystem Process (Multi-Agent Workflow):\\n\\nAgent 1: Retrieves statistical data from economic databases using SQL-based queries. • Agent 2: Searches for relevant academic papers using semantic search tools. • Agent 3: Performs a web search for recent news and policy updates on renewable energy. • Agent 4: Consults a recommendation system to suggest related content, such as reports or expert commentary.\\n\\nResponse: Integrated Response: “Adopting renewable energy in Europe has led to a 20% reduction in greenhouse gas emissions over the past decade, according to EU policy reports. Economically, renewable energy investments have generated approximately 1.2 million jobs, with significant growth in solar and wind sectors. Recent academic studies also highlight potential trade-offs in grid stability and energy storage costs.”\\n\\n5.3 Hierarchical Agentic RAG Systems\\n\\nHierarchical Agentic RAG: [14] systems employ a structured, multi-tiered approach to information retrieval and processing, enhancing both efficiency and strategic decision-making as shown in Figure 18. Agents are organized in a hierarchy, with higher-level agents overseeing and directing lower-level agents. This structure enables multi-level decision-making, ensuring that queries are handled by the most appropriate resources.\\n\\nFigure 18: An illustration of Hierarchical Agentic RAG\\n\\nWorkflow\\n\\n1. Query Reception: A user submits a query, received by a top-tier agent responsible for initial assessment and delegation.\\n\\n2. Strategic Decision-Making: The top-tier agent evaluates the query’s complexity and decides which subor- dinate agents or data sources to prioritize. Certain databases, APIs, or retrieval tools may be deemed more reliable or relevant based on the query’s domain.\\n\\n3. Delegation to Subordinate Agents: The top-tier agent assigns tasks to lower-level agents specialized in particular retrieval methods (e.g., SQL databases, web search, or proprietary systems). These agents execute their assigned tasks independently.\\n\\n18\\n\\n4. Aggregation and Synthesis: The results from subordinate agents are collected and integrated by the higher- level agent, which synthesizes the information into a coherent response.\\n\\n5. Response Delivery: The final, synthesized answer is returned to the user, ensuring that the response is both comprehensive and contextually relevant.\\n\\nKey Features and Advantages.\\n\\nStrategic Prioritization: Top-tier agents can prioritize data sources or tasks based on query complexity, reliability, or context.\\n\\nScalability: Distributing tasks across multiple agent tiers enables handling of highly complex or multi-faceted queries.\\n\\nEnhanced Decision-Making: Higher-level agents apply strategic oversight to improve overall accuracy and coherence of responses.\\n\\nChallenges\\n\\nCoordination Complexity: Maintaining robust inter-agent communication across multiple levels can increase orchestration overhead.\\n\\nResource Allocation: Efficiently distributing tasks among tiers to avoid bottlenecks is non-trivial.\\n\\nUse Case: Financial Analysis System\\n\\nPrompt: What are the best investment options given the current market trends in renewable energy?\\n\\nSystem Process (Hierarchical Agentic Workflow):\\n\\n1. Top-Tier Agent: Assesses the query’s complexity and prioritizes reliable financial databases and economic indicators over less validated data sources.\\n\\n2. Mid-Level Agent: Retrieves real-time market data (e.g., stock prices, sector performance) from proprietary APIs and structured SQL databases.\\n\\n3. Lower-Level Agent(s): Conducts web searches for recent policy announcements and consults recom- mendation systems that track expert opinions and news analytics.\\n\\n4. Aggregation and Synthesis: The top-tier agent compiles the results, integrating quantitative data with policy insights.\\n\\nResponse: Integrated Response: “Based on current market data, renewable energy stocks have shown a 15% growth over the past quarter, driven by supportive government policies and heightened investor interest. Analysts suggest that wind and solar sectors, in particular, may experience continued momentum, while emerging technologies like green hydrogen present moderate risk but potentially high returns.”\\n\\n5.4 Agentic Corrective RAG\\n\\nCorrective RAG : introduces mechanisms to self-correct retrieval results, enhancing document utilization and improving response generation quality as demonstrated in Figure 19. By embedding intelligent agents into the workflow, Corrective RAG [31] [32] ensures iterative refinement of context documents and responses, minimizing errors and maximizing relevance.\\n\\nKey Idea of Corrective RAG: The core principle of Corrective RAG lies in its ability to evaluate retrieved documents dynamically, perform corrective actions, and refine queries to enhance the quality of generated responses. Corrective RAG adjusts its approach as follows:\\n\\nDocument Relevance Evaluation: Retrieved documents are assessed for relevance by the Relevance Evalua- tion Agent. Documents below the relevance threshold trigger corrective steps.\\n\\nQuery Refinement and Augmentation: Queries are refined by the Query Refinement Agent, which leverages semantic understanding to optimize retrieval for better results.\\n\\n19\\n\\nFigure 19: Overview of Agentic Corrective RAG\\n\\nDynamic Retrieval from External Sources: When context is insufficient, the External Knowledge Retrieval Agent performs web searches or accesses alternative data sources to supplement the retrieved documents.\\n\\nResponse Synthesis: All validated and refined information is passed to the Response Synthesis Agent for final response generation.\\n\\nWorkflow: The Corrective RAG system is built on five key agents:\\n\\n1. Context Retrieval Agent: Responsible for retrieving initial context documents from a vector database.\\n\\n2. Relevance Evaluation Agent: Assesses the retrieved documents for relevance and flags any irrelevant or ambiguous documents for corrective actions.\\n\\n3. Query Refinement Agent: Rewrites queries to improve retrieval, leveraging semantic understanding to optimize results.\\n\\n4. External Knowledge Retrieval Agent: Performs web searches or accesses alternative data sources when the context documents are insufficient.\\n\\n5. Response Synthesis Agent: Synthesizes all validated information into a coherent and accurate response.\\n\\nKey Features and Advantages:\\n\\nIterative Correction: Ensures high response accuracy by dynamically identifying and correcting irrelevant or ambiguous retrieval results.\\n\\nDynamic Adaptability: Incorporates real-time web searches and query refinement for enhanced retrieval precision.\\n\\nAgentic Modularity: Each agent performs specialized tasks, ensuring efficient and scalable operation.\\n\\nFactuality Assurance: By validating all retrieved and generated content, Corrective RAG minimizes the risk of hallucination or misinformation.\\n\\n20\\n\\nUse Case: Academic Research Assistant\\n\\nPrompt: What are the latest findings in generative AI research?\\n\\nSystem Process (Corrective RAG Workflow):\\n\\n1. Query Submission: A user submits the query to the system. 2. Context Retrieval:\\n\\nThe Context Retrieval Agent retrieves initial documents from a database of published papers on generative AI.\\n\\nThe retrieved documents are passed to the next step for evaluation.\\n\\n3. Relevance Evaluation:\\n\\nThe Relevance Evaluation Agent assesses the documents for alignment with the query. • Documents are classified into relevant, ambiguous, or irrelevant categories. Irrelevant documents are flagged for corrective actions.\\n\\n4. Corrective Actions (if needed):\\n\\nThe Query Refinement Agent rewrites the query to improve specificity and relevance. • The External Knowledge Retrieval Agent performs web searches to fetch additional papers and reports from external sources.\\n\\n5. Response Synthesis:\\n\\nThe Response Synthesis Agent integrates validated documents into a coherent and comprehensive summary.\\n\\nResponse: Integrated Response: “Recent findings in generative AI highlight advancements in diffusion models, reinforce- ment learning for text-to-video tasks, and optimization techniques for large-scale model training. For more details, refer to studies published in NeurIPS 2024 and AAAI 2025.”\\n\\n5.5 Adaptive Agentic RAG\\n\\nAdaptive Retrieval-Augmented Generation (Adaptive RAG) [33] enhances the flexibility and efficiency of large language models (LLMs) by dynamically adjusting query handling strategies based on the complexity of the incoming query. Unlike static retrieval workflows, Adaptive RAG [34] employs a classifier to assess query complexity and determine the most appropriate approach, ranging from single-step retrieval to multi-step reasoning, or even bypassing retrieval altogether for straightforward queries as illustrated in Figure 20.\\n\\nFigure 20: An Overview of Adaptive Agentic RAG\\n\\nKey Idea of Adaptive RAG The core principle of Adaptive RAG lies in its ability to dynamically tailor retrieval strategies based on the complexity of the query. Adaptive RAG adjusts its approach as follows:\\n\\n21\\n\\nStraightforward Queries: For fact-based questions that require no additional retrieval (e.g., \"What is the boiling point of water?\"), the system directly generates an answer using pre-existing knowledge.\\n\\nSimple Queries: For moderately complex tasks requiring minimal context (e.g., \"What is the status of my latest electricity bill?\"), the system performs a single-step retrieval to fetch the relevant details.\\n\\nComplex Queries: For multi-layered queries requiring iterative reasoning (e.g., \"How has the population of City X changed over the past decade, and what are the contributing factors?\"), the system employs multi-step retrieval, progressively refining intermediate results to provide a comprehensive answer.\\n\\nWorkflow: The Adaptive RAG system is built on three primary components:\\n\\n1. Classifier Role:\\n\\nA smaller language model analyzes the query to predict its complexity.\\n\\nThe classifier is trained using automatically labeled datasets, derived from past model outcomes and query patterns.\\n\\n2. Dynamic Strategy Selection:\\n\\nFor straightforward queries, the system avoids unnecessary retrieval, directly leveraging the LLM for response generation.\\n\\nFor simple queries, it employs a single-step retrieval process to fetch relevant context.\\n\\nFor complex queries, it activates multi-step retrieval to ensure iterative refinement and enhanced reasoning.\\n\\n3. LLM Integration:\\n\\nThe LLM synthesizes retrieved information into a coherent response.\\n\\nIterative interactions between the LLM and the classifier enable refinement for complex queries.\\n\\nKey Features and Advantages\\n\\nDynamic Adaptability: Adjusts retrieval strategies based on query complexity, optimizing both computational efficiency and response accuracy.\\n\\nResource Efficiency: Minimizes unnecessary overhead for simple queries while ensuring thorough processing for complex ones.\\n\\nEnhanced Accuracy: Iterative refinement ensures that complex queries are resolved with high precision.\\n\\nFlexibility: Can be extended to incorporate additional pathways, such as domain-specific tools or external APIs.\\n\\n22\\n\\nUse Case: Customer Support Assistant\\n\\nPrompt: Why is my package delayed, and what alternatives do I have?\\n\\nSystem Process (Adaptive RAG Workflow):\\n\\n1. Query Classification:\\n\\nThe classifier analyzes the query and determines it to be complex, requiring multi-step reasoning.\\n\\n2. Dynamic Strategy Selection:\\n\\nThe system activates a multi-step retrieval process based on the complexity classification.\\n\\n3. Multi-Step Retrieval:\\n\\nRetrieves tracking details from the order database. • Fetches real-time status updates from the shipping provider API. • Conducts a web search for external factors such as weather conditions or local disruptions.\\n\\n4. Response Synthesis:\\n\\nThe LLM integrates all retrieved information, synthesizing a comprehensive and actionable response.\\n\\nResponse: Integrated Response: “Your package is delayed due to severe weather conditions in your region. It is currently at the local distribution center and will be delivered in 2 days. Alternatively, you may opt for a local pickup from the facility.”\\n\\n5.6 Graph-Based Agentic RAG\\n\\n5.6.1 Agent-G: Agentic Framework for Graph RAG\\n\\nAgent-G [8]: introduces a novel agentic architecture that integrates graph knowledge bases with unstructured document retrieval. By combining structured and unstructured data sources, this framework enhances retrieval-augmented generation (RAG) systems with improved reasoning and retrieval accuracy. It employs modular retriever banks, dynamic agent interaction, and feedback loops to ensure high-quality outputs as shown in Figure 21.\\n\\nFigure 21: An Overview of Agent-G: Agentic Framework for Graph RAG [8]\\n\\n23\\n\\nKey Idea of Agent-G The core principle of Agent-G lies in its ability to dynamically assign retrieval tasks to specialized agents, leveraging both graph knowledge bases and textual documents. Agent-G adjusts its retrieval strategy as follows:\\n\\nGraph Knowledge Bases: Structured data is used to extract relationships, hierarchies, and connections (e.g., disease-to-symptom mappings in healthcare).\\n\\nUnstructured Documents: Traditional text retrieval systems provide contextual information to complement graph data.\\n\\nCritic Module: Evaluates the relevance and quality of retrieved information, ensuring alignment with the query.\\n\\nFeedback Loops: Refines retrieval and synthesis through iterative validation and re-querying.\\n\\nWorkflow: The Agent-G system is built on four primary components:\\n\\n1. Retriever Bank:\\n\\nA modular set of agents specializes in retrieving graph-based or unstructured data.\\n\\nAgents dynamically select relevant sources based on the query’s requirements.\\n\\n2. Critic Module:\\n\\nValidates retrieved data for relevance and quality.\\n\\nFlags low-confidence results for re-retrieval or refinement.\\n\\n3. Dynamic Agent Interaction:\\n\\nTask-specific agents collaborate to integrate diverse data types.\\n\\nEnsures cohesive retrieval and synthesis across graph and text sources.\\n\\n4. LLM Integration:\\n\\nSynthesizes validated data into a coherent response.\\n\\nIterative feedback from the critic ensures alignment with the query’s intent.\\n\\nKey Features and Advantages\\n\\nEnhanced Reasoning: Combines structured relationships from graphs with contextual information from unstructured documents.\\n\\nDynamic Adaptability: Adjusts retrieval strategies dynamically based on query requirements.\\n\\nImproved Accuracy: Critic module reduces the risk of irrelevant or low-quality data in responses.\\n\\nScalable Modularity: Supports the addition of new agents for specialized tasks, enhancing scalability.\\n\\n24\\n\\nUse Case: Healthcare Diagnostics\\n\\nPrompt: What are the common symptoms of Type 2 Diabetes, and how are they related to heart disease?\\n\\nSystem Process (Agent-G Workflow):\\n\\n1. Query Reception and Assignment: The system receives the query and identifies the need for both graph-structured and unstructured data to answer the question comprehensively.\\n\\n2. Graph Retriever:\\n\\nExtracts relationships between Type 2 Diabetes and heart disease from a medical knowledge graph.\\n\\nIdentifies shared risk factors such as obesity and high blood pressure by exploring graph hierar- chies and relationships.\\n\\n3. Document Retriever:\\n\\nRetrieves descriptions of Type 2 Diabetes symptoms (e.g., increased thirst, frequent urination, fatigue) from medical literature.\\n\\nAdds contextual information to complement the graph-based insights.\\n\\n4. Critic Module:\\n\\nEvaluates the relevance and quality of the retrieved graph data and document data. • Flags low-confidence results for refinement or re-querying.\\n\\n5. Response Synthesis: The LLM integrates validated data from the Graph Retriever and Document Retriever into a coherent response, ensuring alignment with the query’s intent.\\n\\nResponse: Integrated Response: “Type 2 Diabetes symptoms include increased thirst, frequent urination, and fatigue. Studies show a 50% correlation between diabetes and heart disease, primarily through shared risk factors such as obesity and high blood pressure.”\\n\\n5.6.2 GeAR: Graph-Enhanced Agent for Retrieval-Augmented Generation\\n\\nGeAR [35]: introduces an agentic framework that enhances traditional Retrieval-Augmented Generation (RAG) systems by incorporating graph-based retrieval mechanisms. By leveraging graph expansion techniques and an agent-based architecture, GeAR addresses challenges in multi-hop retrieval scenarios, improving the system’s ability to handle complex queries as shown in Figure 22.\\n\\nKey Idea of GeAR GeAR advances RAG performance through two primary innovations:\\n\\nGraph Expansion: Enhances conventional base retrievers (e.g., BM25) by expanding the retrieval process to include graph-structured data, enabling the system to capture complex relationships and dependencies between entities.\\n\\nAgent Framework: Incorporates an agent-based architecture that utilizes graph expansion to manage retrieval tasks more effectively, allowing for dynamic and autonomous decision-making in the retrieval process.\\n\\nWorkflow: The GeAR system operates through the following components:\\n\\n1. Graph Expansion Module:\\n\\nIntegrates graph-based data into the retrieval process, allowing the system to consider relationships between entities during retrieval.\\n\\nEnhances the base retriever’s ability to handle multi-hop queries by expanding the search space to include\\n\\nconnected entities. 2. Agent-Based Retrieval:\\n\\nEmploys an agent framework to manage the retrieval process, enabling dynamic selection and combination of retrieval strategies based on the query’s complexity.\\n\\nAgents can autonomously decide to utilize graph-expanded retrieval paths to improve the relevance and accuracy of retrieved information.\\n\\n25\\n\\n3. LLM Integration:\\n\\nCombines the retrieved information, enriched by graph expansion, with the capabilities of a Large Language Model (LLM) to generate coherent and contextually relevant responses.\\n\\nThe integration ensures that the generative process is informed by both unstructured documents and structured graph data.\\n\\nFigure 22: An Overview of GeAR: Graph-Enhanced Agent for Retrieval-Augmented Generation[35]\\n\\nKey Features and Advantages\\n\\nEnhanced Multi-Hop Retrieval: GeAR’s graph expansion allows the system to handle complex queries that require reasoning over multiple interconnected pieces of information.\\n\\nAgentic Decision-Making: The agent framework enables dynamic and autonomous selection of retrieval strategies, improving efficiency and relevance.\\n\\nImproved Accuracy: By incorporating structured graph data, GeAR enhances the precision of retrieved information, leading to more accurate and contextually appropriate responses.\\n\\nScalability: The modular nature of the agent framework allows for the integration of additional retrieval strategies and data sources as needed.\\n\\n26\\n\\nUse Case: Multi-Hop Question Answering\\n\\nPrompt: Which author influenced the mentor of J.K. Rowling?\\n\\nSystem Process (GeAR Workflow):\\n\\n1. Top-Tier Agent: Evaluates the query’s multi-hop nature and determines that a combination of graph expansion and document retrieval is necessary to answer the question.\\n\\n2. Graph Expansion Module:\\n\\nIdentifies that J.K. Rowling’s mentor is a key entity in the query. • Traces the literary influences on that mentor by exploring graph-structured data on literary\\n\\nrelationships. 3. Agent-Based Retrieval:\\n\\nAn agent autonomously selects the graph-expanded retrieval path to gather relevant information about the mentor’s influences.\\n\\nIntegrates additional context by querying textual data sources for unstructured details about the mentor and their influences.\\n\\n4. Response Synthesis: Combines insights from the graph and document retrieval processes using the LLM to generate a response that accurately reflects the complex relationships in the query.\\n\\nResponse: Integrated Response: “J.K. Rowling’s mentor, [Mentor Name], was heavily influenced by [Author Name], known for their [notable works or genre]. This connection highlights the layered relationships in literary history, where influential ideas often pass through multiple generations of authors.”\\n\\n5.7 Agentic Document Workflows in Agentic RAG\\n\\nAgentic Document Workflows (ADW) [36] extend traditional Retrieval-Augmented Generation (RAG) paradigms by enabling end-to-end knowledge work automation. These workflows orchestrate complex document-centric processes, integrating document parsing, retrieval, reasoning, and structured outputs with intelligent agents (see Figure 23). ADW systems address limitations of Intelligent Document Processing (IDP) and RAG by maintaining state, coordinating multi-step workflows, and applying domain-specific logic to documents.\\n\\nWorkflow\\n\\n1. Document Parsing and Information Structuring:\\n\\nDocuments are parsed using enterprise-grade tools (e.g., LlamaParse) to extract relevant data fields such as invoice numbers, dates, vendor information, line items, and payment terms.\\n\\nStructured data is organized for downstream processing.\\n\\n2. State Maintenance Across Processes:\\n\\nThe system maintains state about document context, ensuring consistency and relevance across multi-step workflows.\\n\\nTracks the progression of the document through various processing stages.\\n\\n3. Knowledge Retrieval:\\n\\nRelevant references are retrieved from external knowledge bases (e.g., LlamaCloud) or vector indexes. • Retrieves real-time, domain-specific guidelines for enhanced decision-making.\\n\\n4. Agentic Orchestration:\\n\\nIntelligent agents apply business rules, perform multi-hop reasoning, and generate actionable recommen- dations.\\n\\nOrchestrates components such as parsers, retrievers, and external APIs for seamless integration.\\n\\n5. Actionable Output Generation:\\n\\nOutputs are presented in structured formats, tailored to specific use cases. • Recommendations and extracted insights are synthesized into concise and actionable reports.\\n\\n27\\n\\nFigure 23: An Overview of Agentic Document Workflows (ADW) [36]\\n\\nUse Case: Invoice Payments Workflow\\n\\nPrompt: Generate a payment recommendation report based on the submitted invoice and associated vendor contract terms.\\n\\nSystem Process (ADW Workflow):\\n\\n1. Parse the invoice to extract key details such as invoice number, date, vendor information, line items, and payment terms.\\n\\n2. Retrieve the corresponding vendor contract to verify payment terms and identify any applicable discounts or compliance requirements.\\n\\n3. Generate a payment recommendation report that includes original amount due, potential early payment discounts, budget impact analysis, and strategic payment actions.\\n\\nResponse: Integrated Response: \"Invoice INV-2025-045 for $15,000.00 has been processed. An early payment discount of 2% is available if paid by 2025-04-10, reducing the amount due to $14,700.00. A bulk order discount of 5% was applied as the subtotal exceeded $10,000.00. It is recommended to approve early payment to save 2% and ensure timely fund allocation for upcoming project phases.\"\\n\\nKey Features and Advantages\\n\\nState Maintenance: Tracks document context and workflow stage, ensuring consistency across processes.\\n\\nMulti-Step Orchestration: Handles complex workflows involving multiple components and external tools.\\n\\nDomain-Specific Intelligence: Applies tailored business rules and guidelines for precise recommendations.\\n\\nScalability: Supports large-scale document processing with modular and dynamic agent integration.\\n\\nEnhanced Productivity: Automates repetitive tasks while augmenting human expertise in decision-making.\\n\\n28\\n\\n6 Comparative Analysis of Agentic RAG Frameworks\\n\\nTable 2 provides a comprehensive comparative analysis of the three architectural frameworks: Traditional RAG, Agentic RAG, and Agentic Document Workflows (ADW). This analysis highlights their respective strengths, weaknesses, and best-fit scenarios, offering valuable insights into their applicability across diverse use cases.\\n\\nTable 2: Comparative Analysis: Traditional RAG vs Agentic RAG vs Agentic Document Workflows (ADW)\\n\\nFeature\\n\\nFocus\\n\\nContext Maintenance\\n\\nDynamic Adaptability\\n\\nWorkflow Orchestration Use of External Tools/APIs\\n\\nScalability\\n\\nComplex Reasoning\\n\\nPrimary Applications\\n\\nStrengths\\n\\nChallenges\\n\\nTraditional RAG\\n\\nIsolated retrieval and generation tasks\\n\\nLimited\\n\\nMinimal\\n\\nAbsent\\n\\nBasic integration (e.g., retrieval tools)\\n\\nLimited to small datasets or queries Basic (e.g., simple Q&A) QA systems, knowledge retrieval\\n\\nSimplicity, quick setup\\n\\nPoor contextual understanding\\n\\nAgentic RAG\\n\\nMulti-agent collaboration and reasoning Enabled through memory modules High\\n\\nOrchestrates multi-agent tasks Extends via tools like APIs and knowledge bases Scalable for multi-agent systems Multi-step reasoning with agents Multi-domain knowledge and reasoning High accuracy, collaborative reasoning Coordination complexity\\n\\nAgentic Document Workflows (ADW) Document-centric end-to-end workflows\\n\\nMaintains state across multi-step workflows Tailored to document workflows Integrates multi-step document processing Deeply integrates business rules and domain-specific tools Scales for multi-domain enterprise workflows Structured reasoning across documents Contract review, invoice processing, claims analysis\\n\\nEnd-to-end automation, domain-specific intelligence Resource overhead, domain standardization\\n\\nThe comparative analysis underscores the evolutionary trajectory from Traditional RAG to Agentic RAG and further to Agentic Document Workflows (ADW). While Traditional RAG offers simplicity and ease of deployment for basic tasks, Agentic RAG introduces enhanced reasoning and scalability through multi-agent collaboration. ADW builds upon these advancements by providing robust, document-centric workflows that facilitate end-to-end automation and integration with domain-specific processes. Understanding the strengths and limitations of each framework is crucial for selecting the most appropriate architecture to meet specific application requirements and operational demands.\\n\\n7 Applications of Agentic RAG\\n\\nAgentic Retrieval-Augmented Generation (RAG) systems have demonstrated transformative potential across a variety of domains. By combining real-time data retrieval, generative capabilities, and autonomous decision-making, these systems address complex, dynamic, and multi-modal challenges. This section explores the key applications of Agentic RAG, providing detailed insights into how these systems are shaping industries such as customer support, healthcare, finance, education, legal workflows, and creative industries.\\n\\n7.1 Customer Support and Virtual Assistants\\n\\nAgentic RAG systems are revolutionizing customer support by enabling real-time, context-aware query resolution. Traditional chatbots and virtual assistants often rely on static knowledge bases, leading to generic or outdated responses.\\n\\n29\\n\\nBy contrast, Agentic RAG systems dynamically retrieve the most relevant information, adapt to the user’s context, and generate personalized responses.\\n\\nUse Case: Twitch Ad Sales Enhancement [37] For instance, Twitch leveraged an agentic workflow with RAG on Amazon Bedrock to streamline ad sales. The system dynamically retrieved advertiser data, historical campaign performance, and audience demographics to generate detailed ad proposals, significantly boosting operational efficiency.\\n\\nKey Benefits:\\n\\nImproved Response Quality: Personalized and context-aware replies enhance user engagement.\\n\\nOperational Efficiency: Reduces the workload on human support agents by automating complex queries.\\n\\nReal-Time Adaptability: Dynamically integrates evolving data, such as live service outages or pricing updates.\\n\\n7.2 Healthcare and Personalized Medicine\\n\\nIn healthcare, the integration of patient-specific data with the latest medical research is critical for informed decision- making. Agentic RAG systems enable this by retrieving real-time clinical guidelines, medical literature, and patient history to assist clinicians in diagnostics and treatment planning.\\n\\nUse Case: Patient Case Summary [38] Agentic RAG systems have been applied in generating patient case summaries. For example, by integrating electronic health records (EHR) and up-to-date medical literature, the system generates comprehensive summaries for clinicians to make faster and more informed decisions.\\n\\nKey Benefits:\\n\\nPersonalized Care: Tailors recommendations to individual patient needs.\\n\\nTime Efficiency: Streamlines the retrieval of relevant research, saving valuable time for healthcare providers.\\n\\nAccuracy: Ensures recommendations are based on the latest evidence and patient-specific parameters.\\n\\n7.3 Legal and Contract Analysis\\n\\nAgentic RAG systems are redefining how legal workflows are conducted, offering tools for rapid document analysis and decision-making.\\n\\nUse Case: Contract Review [39] A legal agentic RAG system can analyze contracts, extract critical clauses, and identify potential risks. By combining semantic search capabilities with legal knowledge graphs, it automates the tedious process of contract review, ensuring compliance and mitigating risks.\\n\\nKey Benefits:\\n\\nRisk Identification: Automatically flags clauses that deviate from standard terms.\\n\\nEfficiency: Reduces the time spent on contract review processes.\\n\\nScalability: Handles large volumes of contracts simultaneously.\\n\\n7.4 Finance and Risk Analysis\\n\\nAgentic RAG systems are transforming the finance industry by providing real-time insights for investment decisions, market analysis, and risk management. These systems integrate live data streams, historical trends, and predictive modeling to generate actionable outputs.\\n\\nUse Case: Auto Insurance Claims Processing [40] In auto insurance, Agentic RAG can automate claim processing. For example, by retrieving policy details and combining them with accident data, it generates claim recommendations while ensuring compliance with regulatory requirements.\\n\\nKey Benefits:\\n\\nReal-Time Analytics: Delivers insights based on live market data.\\n\\n30\\n\\nRisk Mitigation: Identifies potential risks using predictive analysis and multi-step reasoning. • Enhanced Decision-Making: Combines historical and live data for comprehensive strategies.\\n\\n7.5 Education and Personalized Learning\\n\\nEducation is another domain where Agentic RAG systems are making significant strides. These systems enable adaptive learning by generating explanations, study materials, and feedback tailored to the learner’s progress and preferences.\\n\\nUse Case: Research Paper Generation [41] In higher education, Agentic RAG has been used to assist researchers by synthesizing key findings from multiple sources. For instance, a researcher querying, “What are the latest advancements in quantum computing?” receives a concise summary enriched with references, enhancing the quality and efficiency of their work.\\n\\nKey Benefits:\\n\\nTailored Learning Paths: Adapts content to individual student needs and performance levels. • Engaging Interactions: Provides interactive explanations and personalized feedback. • Scalability: Supports large-scale deployments for diverse educational environments.\\n\\n7.6 Graph-Enhanced Applications in Multimodal Workflows\\n\\nGraph-Enhanced Agentic RAG (GEAR) combines graph structures with retrieval mechanisms, making it particularly effective in multimodal workflows where interconnected data sources are essential.\\n\\nUse Case: Market Survey Generation GEAR enables the synthesis of text, images, and videos for marketing campaigns. For example, querying, “What are the emerging trends in eco-friendly products?” generates a detailed report enriched with customer preferences, competitor analysis, and multimedia content.\\n\\nKey Benefits:\\n\\nMulti-Modal Capabilities: Integrates text, image, and video data for comprehensive outputs. • Enhanced Creativity: Generates innovative ideas and solutions for marketing and entertainment. • Dynamic Adaptability: Adapts to evolving market trends and customer needs.\\n\\nThe applications of Agentic RAG systems span a wide range of industries, showcasing their versatility and transformative potential. From personalized customer support to adaptive education and graph-enhanced multimodal workflows, these systems address complex, dynamic, and knowledge-intensive challenges. By integrating retrieval, generation, and agentic intelligence, Agentic RAG systems are paving the way for next-generation AI applications.\\n\\n8 Tools and Frameworks for Agentic RAG\\n\\nAgentic Retrieval-Augmented Generation (RAG) systems represent a significant evolution in combining retrieval, generation, and agentic intelligence. These systems extend the capabilities of traditional RAG by integrating decision- making, query reformulation, and adaptive workflows. The following tools and frameworks provide robust support for developing Agentic RAG systems, addressing the complex requirements of real-world applications.\\n\\nKey Tools and Frameworks:\\n\\nLangChain and LangGraph: LangChain [42] provides modular components for building RAG pipelines, seamlessly integrating retrievers, generators, and external tools. LangGraph complements this by introducing graph-based workflows that support loops, state persistence, and human-in-the-loop interactions, enabling sophisticated orchestration and self-correction mechanisms in agentic systems.\\n\\nLlamaIndex: LlamaIndex’s [43] Agentic Document Workflows (ADW) enable end-to-end automation of document processing, retrieval, and structured reasoning. It introduces a meta-agent architecture where sub-agents manage smaller document sets, coordinating through a top-level agent for tasks such as compliance analysis and contextual understanding.\\n\\nHugging Face Transformers and Qdrant: Hugging Face [44] offers pre-trained models for embedding and generation tasks, while Qdrant [45] enhances retrieval workflows with adaptive vector search capabilities, allowing agents to optimize performance by dynamically switching between sparse and dense vector methods.\\n\\n31\\n\\nCrewAI and AutoGen: These frameworks emphasize multi-agent architectures. CrewAI [46] supports hierarchical and sequential processes, robust memory systems, and tool integrations. AG2 [47] (formerly knows as AutoGen [48, 49]) excels in multi-agent collaboration with advanced support for code generation, tool execution, and decision-making.\\n\\nOpenAI Swarm Framework: An educational framework designed for ergonomic, lightweight multi-agent orchestration [50], emphasizing agent autonomy and structured collaboration.\\n\\nAgentic RAG with Vertex AI: Developed by Google, Vertex AI [51] integrates seamlessly with Agentic Retrieval-Augmented Generation (RAG), providing a platform to build, deploy, and scale machine learning models while leveraging advanced AI capabilities for robust, contextually aware retrieval and decision-making workflows.\\n\\nSemantic Kernel: Semantic Kernel [52, 53] is an open-source SDK by Microsoft that integrates large language models (LLMs) into applications. It supports agentic patterns, enabling the creation of autonomous AI agents for natural language understanding, task automation, and decision-making. It has been used in scenarios like ServiceNow’s P1 incident management to facilitate real-time collaboration, automate task execution, and retrieve contextual information seamlessly\\n\\nAmazon Bedrock for Agentic RAG: Amazon Bedrock [37] provides a robust platform for implementing Agentic Retrieval-Augmented Generation (RAG) workflows.\\n\\nIBM Watson and Agentic RAG: IBM’s watsonx.ai [54] supports building Agentic RAG systems, exemplified by using the Granite-3-8B-Instruct model to answer complex queries by integrating external information and enhancing response accuracy.\\n\\nNeo4j and Vector Databases: Neo4j, a prominent open-source graph database, excels in handling complex relationships and semantic queries. Alongside Neo4j, vector databases like Weaviate, Pinecone, Milvus, and Qdrant provide efficient similarity search and retrieval capabilities, forming the backbone of high-performance Agentic Retrieval-Augmented Generation (RAG) workflows.\\n\\n9 Benchmarks and Datasets\\n\\nCurrent benchmarks and datasets provide valuable insights into evaluating Retrieval-Augmented Generation (RAG) systems, including those with agentic and graph-based enhancements. While some are explicitly designed for RAG, others are adapted to test retrieval, reasoning, and generation capabilities in diverse scenarios. Datasets are crucial for testing the retrieval, reasoning, and generation components of RAG systems. Table 3 discusses some key datasets based on the dowstream task for RAG Evaluation.\\n\\nBenchmarks play a critical role in standardizing the evaluation of RAG systems by providing structured tasks and metrics. The following benchmarks are particularly relevant:\\n\\nBEIR (Benchmarking Information Retrieval): A versatile benchmark designed for evaluating embedding models on a variety of information retrieval tasks, encompassing 17 datasets across diverse domains like bioinformatics, finance, and question answering [55].\\n\\nMS MARCO (Microsoft Machine Reading Comprehension): Focused on passage ranking and question answering, this benchmark is widely used for dense retrieval tasks in RAG systems [56].\\n\\nTREC (Text REtrieval Conference, Deep Learning Track): Provides datasets for passage and document retrieval, emphasizing the quality of ranking models in retrieval pipelines [57].\\n\\nMuSiQue (Multihop Sequential Questioning): A benchmark for multihop reasoning across multiple documents, emphasizing the importance of retrieving and synthesizing information from disconnected contexts [58].\\n\\n2WikiMultihopQA: A dataset designed for multihop QA tasks over two Wikipedia articles, focusing on the ability to connect knowledge across multiple sources [59].\\n\\nAgentG (Agentic RAG for Knowledge Fusion): Tailored for agentic RAG tasks, this benchmark assesses dynamic information synthesis across multiple knowledge bases [8].\\n\\nHotpotQA: A multi-hop QA benchmark requiring retrieval and reasoning over interconnected contexts, ideal for evaluating complex RAG workflows[60].\\n\\nRAGBench: A large-scale, explainable benchmark featuring 100,000 examples across industry domains, with a TRACe evaluation framework for actionable RAG metrics [61].\\n\\n32\\n\\nBERGEN (Benchmarking Retrieval-Augmented Generation): A library for systematically benchmarking RAG systems with standardized experiments [62].\\n\\nFlashRAG Toolkit: Implements 12 RAG methods and includes 32 benchmark datasets to support efficient and standardized RAG evaluation [63].\\n\\nGNN-RAG: This benchmark evaluates graph-based RAG systems on tasks like node-level and edge-level predictions, focusing on retrieval quality and reasoning performance in Knowledge Graph Question Answering (KGQA) [64].\\n\\nTable 3: Downstream Tasks and Datasets for RAG Evaluation (Adapted from [20]\\n\\nCategory\\n\\nQA\\n\\nGraph-based QA\\n\\nDialog\\n\\nRecommendation\\n\\nReasoning\\n\\nOthers\\n\\nSummarization\\n\\nText Generation\\n\\nText Classification\\n\\nCode Search\\n\\nRobustness\\n\\nDatasets and References Natural Questions (NQ) [65], TriviaQA [66], SQuAD [67], Web Questions (WebQ) [68], PopQA [69], MS MARCO [56] HotpotQA [60], 2WikiMultiHopQA [59], MuSiQue [58] ELI5 [70], NarrativeQA (NQA) [71], ASQA [72], QM- Sum [73] Qasper [74], COVID-QA [75], CMB/MMCU Medical [76] QuALITY [77], ARC (No reference available), Common- senseQA [78] GraphQA [79] Graph QA WikiEvent [80], RAMS [81] Event Argument Extraction Wizard of Wikipedia (WoW) [82] Open-domain Dialog KBP [83], DuleMon [84] Personalized Dialog CamRest [85] Task-oriented Dialog Amazon Datasets (Toys, Sports, Beauty) [86] Personalized Content HellaSwag [87], CommonsenseQA [78] Commonsense Reasoning CoT Reasoning [88] CoT Reasoning CSQA [89] Complex Reasoning MMLU (No reference available), WikiText-103 [65] Language Understanding FEVER [90], PubHealth [91] Fact Checking/Verification StrategyQA [92] Strategy QA WikiASP [93], XSum [94] Text Summarization NarrativeQA (NQA) [71], QMSum [73] Long-form Summarization Biography Dataset (No reference available) Biography SST-2 [95] Sentiment Analysis VioLens[96], TREC [57] General Classification CodeSearchNet [97] Programming Search Retrieval Robustness NoMIRACL [98] Language Modeling Robustness WikiText-103 [99] Math Reasoning Translation Tasks\\n\\nTask Type Single-hop QA\\n\\nMulti-hop QA Long-form QA\\n\\nDomain-specific QA\\n\\nMulti-choice QA\\n\\nMath Machine Translation\\n\\nGSM8K [100] JRC-Acquis [101]\\n\\n10 Conclusion\\n\\nAgentic Retrieval-Augmented Generation (RAG) represents a transformative advancement in artificial intelligence, addressing the limitations of traditional RAG systems through the integration of autonomous agents. By leveraging\\n\\n33\\n\\nagentic intelligence, these systems introduce capabilities such as dynamic decision-making, iterative reasoning, and collaborative workflows, enabling them to tackle complex, real-world tasks with enhanced precision and adaptability.\\n\\nThis survey explored the evolution of RAG systems, from their initial implementations to advanced paradigms like Modular RAG, highlighting the contributions and limitations of each. The integration of agents into the RAG pipeline has emerged as a pivotal development, resulting in Agentic RAG systems that overcome static workflows and limited contextual adaptability. Applications across healthcare, finance, education, and creative industries demonstrate the transformative potential of these systems, showcasing their ability to deliver personalized, real-time, and context-aware solutions.\\n\\nDespite their promise, Agentic RAG systems face challenges that require further research and innovation. Coordination complexity in multi-agent architectures, scalability, and latency issues, as well as ethical considerations, must be addressed to ensure robust and responsible deployment. Additionally, the lack of specialized benchmarks and datasets tailored to evaluate agentic capabilities poses a significant hurdle. Developing evaluation methodologies that capture the unique aspects of Agentic RAG, such as multi-agent collaboration and dynamic adaptability, will be crucial for advancing the field.\\n\\nLooking ahead, the convergence of retrieval-augmented generation and agentic intelligence has the potential to redefine AI’s role in dynamic and complex environments. By addressing these challenges and exploring future directions, researchers and practitioners can unlock the full potential of Agentic RAG systems, paving the way for transformative applications across industries and domains. As AI systems continue to evolve, Agentic RAG stands as a cornerstone for creating adaptive, context-aware, and impactful solutions that meet the demands of a rapidly changing world.\\n\\nReferences\\n\\n[1] Shervin Minaee, Tomas Mikolov, Narjes Nikzad, Meysam Chenaghlu, Richard Socher, Xavier Amatriain, and\\n\\nJianfeng Gao. Large language models: A survey, 2024.\\n\\n[2] Aditi Singh. Exploring language models: A comprehensive survey and analysis. In 2023 International Con- ference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE), pages 1–4, 2023.\\n\\n[3] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. A survey of large language models, 2024.\\n\\n[4] Sumit Kumar Dam, Choong Seon Hong, Yu Qiao, and Chaoning Zhang. A complete survey on llm-based ai\\n\\nchatbots, 2024.\\n\\n[5] Aditi Singh. A survey of ai text-to-image and ai text-to-video generators. In 2023 4th International Conference\\n\\non Artificial Intelligence, Robotics and Control (AIRC), pages 32–36, 2023.\\n\\n[6] Aditi Singh, Abul Ehtesham, Gaurav Kumar Gupta, Nikhil Kumar Chatta, Saket Kumar, and Tala Talaei Khoei.\\n\\nExploring prompt engineering: A systematic review with swot analysis, 2024.\\n\\n[7] Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions. ACM Transactions on Information Systems, November 2024.\\n\\n[8] Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, and Christos Faloutsos. Agent-g: An agentic framework for graph retrieval augmented generation, 2024.\\n\\n[9] Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang, Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang, Jie Jiang, and Bin Cui. Retrieval-augmented generation for ai-generated content: A survey, 2024.\\n\\n[10] Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan,\\n\\nand Graham Neubig. Active retrieval augmented generation, 2023.\\n\\n[11] Yikun Han, Chunjiang Liu, and Pengfei Wang. A comprehensive survey on vector database: Storage and retrieval\\n\\ntechnique, challenge, 2023.\\n\\n[12] Anthropic.\\n\\nBuilding\\n\\neffective\\n\\nagents,\\n\\n2024.\\n\\nhttps://www.anthropic.com/research/\\n\\nbuilding-effective-agents. Accessed: February 2, 2025.\\n\\n[13] LangChain. Langgraph workflows tutorial, 2025.\\n\\nhttps://langchain-ai.github.io/langgraph/\\n\\ntutorials/workflows/. Accessed: February 2, 2025.\\n\\n34\\n\\n[14] Chidaksh Ravuru, Sagar Srinivas Sakhinana, and Venkataramana Runkana. Agentic retrieval-augmented\\n\\ngeneration for time series analysis, 2024.\\n\\n[15] Jie Huang and Kevin Chen-Chuan Chang. Towards reasoning in large language models: A survey, 2023.\\n\\n[16] Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, and Siliang Tang.\\n\\nGraph retrieval-augmented generation: A survey, 2024.\\n\\n[17] Aditi Singh, Abul Ehtesham, Saifuddin Mahmud, and Jong-Hoon Kim. Revolutionizing mental health care In 2024 IEEE 14th Annual Computing and\\n\\nthrough langchain: A journey with a large language model. Communication Workshop and Conference (CCWC), pages 0073–0078, 2024.\\n\\n[18] Gaurav Kumar Gupta, Aditi Singh, Sijo Valayakkad Manikandan, and Abul Ehtesham. Digital diagnostics: The\\n\\npotential of large language models in recognizing symptoms of common illnesses. AI, 6(1), 2025.\\n\\n[19] Aditi Singh, Abul Ehtesham, Saket Kumar, Gaurav Kumar Gupta, and Tala Talaei Khoei. Encouraging responsible use of generative ai in education: A reward-based learning approach. In Tim Schlippe, Eric C. K. Cheng, and Tianchong Wang, editors, Artificial Intelligence in Education Technologies: New Development and Innovative Practices, pages 404–413, Singapore, 2025. Springer Nature Singapore.\\n\\n[20] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Meng Wang, and\\n\\nHaofen Wang. Retrieval-augmented generation for large language models: A survey, 2024.\\n\\n[21] Vladimir Karpukhin, Barlas O˘guz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen\\n\\ntau Yih. Dense passage retrieval for open-domain question answering, 2020.\\n\\n[22] Zeyu Zhang, Xiaohe Bo, Chen Ma, Rui Li, Xu Chen, Quanyu Dai, Jieming Zhu, Zhenhua Dong, and Ji-Rong\\n\\nWen. A survey on the memory mechanism of large language model based agents, 2024.\\n\\n[23] Zhibin Gou, Zhihong Shao, Yeyun Gong, Yelong Shen, Yujiu Yang, Nan Duan, and Weizhu Chen. Critic: Large\\n\\nlanguage models can self-correct with tool-interactive critiquing, 2024.\\n\\n[24] Xu Huang, Weiwen Liu, Xiaolong Chen, Xingmei Wang, Hao Wang, Defu Lian, Yasheng Wang, Ruiming Tang,\\n\\nand Enhong Chen. Understanding the planning of llm agents: A survey, 2024.\\n\\n[25] Aditi Singh, Abul Ehtesham, Saket Kumar, and Tala Talaei Khoei. Enhancing ai systems with agentic workflows patterns in large language model. In 2024 IEEE World AI IoT Congress (AIIoT), pages 527–532, 2024.\\n\\n[26] DeepLearning.AI. How agents can improve llm performance. https://www.deeplearning.ai/the-batch/ Ac-\\n\\nhow-agents-can-improve-llm-performance/?ref=dl-staging-website.ghost.io, 2024. cessed: 2025-01-13.\\n\\n[27] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. Self-refine: Iterative refinement with self-feedback, 2023.\\n\\n[28] Noah Shinn, Federico Cassano, Edward Berman, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.\\n\\nReflexion: Language agents with verbal reinforcement learning, 2023.\\n\\n[29] Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, Olaf Wiest, and Xiangliang Zhang. Large language model based multi-agents: A survey of progress and challenges, 2024.\\n\\n[30] Weaviate Blog. What is agentic rag? https://weaviate.io/blog/what-is-agentic-rag#:~:text=is% 20Agentic%20RAG%3F-,%E2%80%8B,of%20the%20non%2Dagentic%20pipeline. Accessed: 2025-01-14.\\n\\n[31] Shi-Qi Yan, Jia-Chen Gu, Yun Zhu, and Zhen-Hua Ling. Corrective retrieval augmented generation, 2024.\\n\\n[32] LangGraph CRAG Tutorial. Langgraph crag: Contextualized retrieval-augmented generation tutorial. https:\\n\\n//langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag/. Accessed: 2025-01-14.\\n\\n[33] Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, and Jong C. Park. Adaptive-rag: Learning to adapt\\n\\nretrieval-augmented large language models through question complexity, 2024.\\n\\n[34] LangGraph Adaptive RAG Tutorial. Langgraph adaptive rag: Adaptive retrieval-augmented generation tu- torial. https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_adaptive_rag/. Accessed: 2025-01-14.\\n\\n[35] Zhili Shen, Chenxin Diao, Pavlos Vougiouklis, Pascual Merita, Shriram Piramanayagam, Damien Graux, Dandan Tu, Zeren Jiang, Ruofei Lai, Yang Ren, and Jeff Z. Pan. Gear: Graph-enhanced agent for retrieval-augmented generation, 2024.\\n\\n[36] LlamaIndex.\\n\\nIntroducing agentic document workflows. introducing-agentic-document-workflows, 2025. Accessed: 2025-01-13.\\n\\nhttps://www.llamaindex.ai/blog/\\n\\n35\\n\\n[37] AWS Machine Learning Blog.\\n\\nHow twitch used agentic workflow with rag on amazon https://aws.amazon.com/blogs/machine-learning/\\n\\nbedrock how-twitch-used-agentic-workflow-with-rag-on-amazon-bedrock-to-supercharge-ad-sales/, 2025. Accessed: 2025-01-13.\\n\\nto\\n\\nsupercharge\\n\\nad\\n\\nsales.\\n\\n[38] LlamaCloud Demo Repository.\\n\\nPatient case summary workflow using llamacloud.\\n\\nhttps:\\n\\n//github.com/run-llama/llamacloud-demo/blob/main/examples/document_workflows/ patient_case_summary/patient_case_summary.ipynb, 2025. Accessed: 2025-01-13.\\n\\n[39] LlamaCloud Demo Repository. Contract review workflow using llamacloud.\\n\\nhttps://github.com/\\n\\nrun-llama/llamacloud-demo/blob/main/examples/document_workflows/contract_review/ contract_review.ipynb, 2025. Accessed: 2025-01-13.\\n\\n[40] LlamaCloud Demo Repository.\\n\\nAuto insurance claims workflow using llamacloud.\\n\\nhttps:\\n\\n//github.com/run-llama/llamacloud-demo/blob/main/examples/document_workflows/auto_ insurance_claims/auto_insurance_claims.ipynb, 2025. Accessed: 2025-01-13.\\n\\n[41] LlamaCloud Demo Repository.\\n\\nResearch paper\\n\\nreport generation workflow using llamacloud.\\n\\nhttps://github.com/run-llama/llamacloud-demo/blob/main/examples/report_generation/ research_paper_report_generation.ipynb, 2025. Accessed: 2025-01-13.\\n\\n[42] LangGraph Agentic RAG Tutorial. Langgraph agentic rag: Nodes and edges tutorial. https://langchain-ai. Accessed:\\n\\ngithub.io/langgraph/tutorials/rag/langgraph_agentic_rag/#nodes-and-edges. 2025-01-14.\\n\\n[43] LlamaIndex Blog.\\n\\nAgentic\\n\\nrag with\\n\\nllamaindex.\\n\\nhttps://www.llamaindex.ai/blog/\\n\\nagentic-rag-with-llamaindex-2721b8a49ff6. Accessed: 2025-01-14.\\n\\n[44] Hugging Face Cookbook. Agentic rag: Turbocharge your retrieval-augmented generation with query reformula- tion and self-query. https://huggingface.co/learn/cookbook/en/agent_rag. Accessed: 2025-01-14. [45] Qdrant Blog. Agentic rag: Combining rag with agents for enhanced information retrieval. https://qdrant.\\n\\ntech/articles/agentic-rag/. Accessed: 2025-01-14.\\n\\n[46] crewAI Inc. crewai: A github repository for ai projects. https://github.com/crewAIInc/crewAI, 2025.\\n\\nAccessed: 2025-01-15.\\n\\n[47] AG2AI Contributors. Ag2: A github repository for advanced generative ai research. https://github.com/\\n\\nag2ai/ag2, 2025. Accessed: 2025-01-15.\\n\\n[48] Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah, Ryen W White, Doug Burger, and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent conversation framework. 2023.\\n\\n[49] Shaokun Zhang, Jieyu Zhang, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, and Qingyun Wu. Training\\n\\nlanguage model agents without modifying language models. ICML’24, 2024.\\n\\n[50] OpenAI. Swarm: Lightweight multi-agent orchestration framework. https://github.com/openai/swarm.\\n\\nAccessed: 2025-01-14.\\n\\n[51] LlamaIndex Documentation. Agentic rag using vertex ai. https://docs.llamaindex.ai/en/stable/\\n\\nexamples/agent/agentic_rag_using_vertex_ai/. Accessed: 2025-01-14.\\n\\n[52] Microsoft. Semantic kernel overview, 2025. https://learn.microsoft.com/en-us/semantic-kernel/\\n\\noverview/. Accessed: February 2, 2025.\\n\\n[53] Microsoft. Semantic kernel github repository, 2025. https://github.com/microsoft/semantic-kernel.\\n\\nAccessed: February 2, 2025.\\n\\n[54] IBM Granite Community. Agentic rag: Ai agents with ibm granite models. https://github.com/ ibm-granite-community/granite-snack-cookbook/blob/main/recipes/AI-Agents/Agentic_ RAG.ipynb. Accessed: 2025-01-14.\\n\\n[55] Nandan Thakur, Nils Reimers, Andreas Rücklé, Abhishek Srivastava, and Iryna Gurevych. Beir: A heterogenous\\n\\nbenchmark for zero-shot evaluation of information retrieval models, 2021.\\n\\n[56] Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. Ms marco: A human generated machine reading comprehension dataset, 2018.\\n\\n[57] Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos, Jimmy Lin, Ellen M. Voorhees, and Ian Soboroff. Overview of the trec 2022 deep learning track. In Text REtrieval Conference (TREC). NIST, TREC, March 2023.\\n\\n36\\n\\n[58] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Musique: Multihop questions\\n\\nvia single-hop question composition, 2022.\\n\\n[59] Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. Constructing a multi-hop qa dataset\\n\\nfor comprehensive evaluation of reasoning steps, 2020.\\n\\n[60] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W. Cohen, Ruslan Salakhutdinov, and Christo-\\n\\npher D. Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering, 2018.\\n\\n[61] Robert Friel, Masha Belyi, and Atindriyo Sanyal. Ragbench: Explainable benchmark for retrieval-augmented\\n\\ngeneration systems, 2024.\\n\\n[62] David Rau, Hervé Déjean, Nadezhda Chirkova, Thibault Formal, Shuai Wang, Vassilina Nikoulina, and Stéphane\\n\\nClinchant. Bergen: A benchmarking library for retrieval-augmented generation, 2024.\\n\\n[63] Jiajie Jin, Yutao Zhu, Xinyu Yang, Chenghao Zhang, and Zhicheng Dou. Flashrag: A modular toolkit for efficient\\n\\nretrieval-augmented generation research, 2024.\\n\\n[64] Costas Mavromatis and George Karypis. Gnn-rag: Graph neural retrieval for large language model reasoning,\\n\\n2024.\\n\\n[65] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7:452–466, 2019.\\n\\n[66] Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke Zettlemoyer. Triviaqa: A large scale distantly supervised\\n\\nchallenge dataset for reading comprehension, 2017.\\n\\n[67] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for machine\\n\\ncomprehension of text, 2016.\\n\\n[68] Jonathan Berant, Andrew K. Chou, Roy Frostig, and Percy Liang. Semantic parsing on freebase from question-\\n\\nanswer pairs. In Conference on Empirical Methods in Natural Language Processing, 2013.\\n\\n[69] Alex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. When not to trust language models: Investigating effectiveness of parametric and non-parametric memories. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 9802–9822, Toronto, Canada, July 2023. Association for Computational Linguistics.\\n\\n[70] Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. Eli5: Long form\\n\\nquestion answering, 2019.\\n\\n[71] Tomáš Koˇciský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward\\n\\nGrefenstette. The narrativeqa reading comprehension challenge. 2017.\\n\\n[72] Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-Wei Chang. Asqa: Factoid questions meet long-form\\n\\nanswers, 2023.\\n\\n[73] Ming Zhong, Da Yin, Tao Yu, Ahmad Zaidi, Mutethia Mutuma, Rahul Jha, Ahmed Hassan Awadallah, Asli Celikyilmaz, Yang Liu, Xipeng Qiu, and Dragomir Radev. QMSum: A new benchmark for query-based multi-domain meeting summarization. pages 5905–5921, June 2021.\\n\\n[74] Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan, Noah A. Smith, and Matt Gardner. A dataset of information- seeking questions and answers anchored in research papers. In Kristina Toutanova, Anna Rumshisky, Luke Zettlemoyer, Dilek Hakkani-Tur, Iz Beltagy, Steven Bethard, Ryan Cotterell, Tanmoy Chakraborty, and Yichao Zhou, editors, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4599–4610, Online, June 2021. Association for Computational Linguistics.\\n\\n[75] Timo Möller, Anthony Reina, Raghavan Jayakumar, and Malte Pietsch. COVID-QA: A question answering dataset for COVID-19. In ACL 2020 Workshop on Natural Language Processing for COVID-19 (NLP-COVID), 2020.\\n\\n[76] Xidong Wang, Guiming Hardy Chen, Dingjie Song, Zhiyi Zhang, Zhihong Chen, Qingying Xiao, Feng Jiang, Jianquan Li, Xiang Wan, Benyou Wang, and Haizhou Li. Cmb: A comprehensive medical benchmark in chinese, 2024.\\n\\n[77] Richard Yuanzhe Pang, Alicia Parrish, Nitish Joshi, Nikita Nangia, Jason Phang, Angelica Chen, Vishakh Padmakumar, Johnny Ma, Jana Thompson, He He, and Samuel R. Bowman. Quality: Question answering with long input texts, yes!, 2022.\\n\\n37\\n\\n[78] Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. CommonsenseQA: A question answering challenge targeting commonsense knowledge. In Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4149–4158, Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.\\n\\n[79] Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V. Chawla, Thomas Laurent, Yann LeCun, Xavier Bresson, and Bryan Hooi. G-retriever: Retrieval-augmented generation for textual graph understanding and question answering, 2024.\\n\\n[80] Sha Li, Heng Ji, and Jiawei Han. Document-level event argument extraction by conditional generation, 2021.\\n\\n[81] Seth Ebner, Patrick Xia, Ryan Culkin, Kyle Rawlins, and Benjamin Van Durme. Multi-sentence argument\\n\\nlinking, 2020.\\n\\n[82] Emily Dinan, Stephen Roller, Kurt Shuster, Angela Fan, Michael Auli, and Jason Weston. Wizard of wikipedia:\\n\\nKnowledge-powered conversational agents, 2019.\\n\\n[83] Hongru Wang, Minda Hu, Yang Deng, Rui Wang, Fei Mi, Weichao Wang, Yasheng Wang, Wai-Chung Kwan, Irwin King, and Kam-Fai Wong. Large language models as source planner for personalized knowledge-grounded dialogue, 2023.\\n\\n[84] Xinchao Xu, Zhibin Gou, Wenquan Wu, Zheng-Yu Niu, Hua Wu, Haifeng Wang, and Shihang Wang. Long time\\n\\nno see! open-domain conversation with long-term persona memory, 2022.\\n\\n[85] Tsung-Hsien Wen, Milica Gaši´c, Nikola Mrkši´c, Lina M. Rojas-Barahona, Pei-Hao Su, Stefan Ultes, David Vandyke, and Steve Young. Conditional generation and snapshot learning in neural dialogue systems. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2153–2162, Austin, Texas, November 2016. Association for Computational Linguistics.\\n\\n[86] Ruining He and Julian McAuley. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In Proceedings of the 25th International Conference on World Wide Web, WWW ’16, page 507–517, Republic and Canton of Geneva, CHE, 2016. International World Wide Web Conferences Steering Committee.\\n\\n[87] Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. HellaSwag: Can a machine really finish your sentence? In Anna Korhonen, David Traum, and Lluís Màrquez, editors, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4791–4800, Florence, Italy, July 2019. Association for Computational Linguistics.\\n\\n[88] Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, Jamin Shin, and Minjoon Seo. The cot collection: Improving zero-shot and few-shot learning of language models via chain-of-thought fine-tuning, 2023.\\n\\n[89] Amrita Saha, Vardaan Pahuja, Mitesh M. Khapra, Karthik Sankaranarayanan, and Sarath Chandar. Complex sequential question answering: Towards learning to converse over linked question answer pairs with a knowledge graph. 2018.\\n\\n[90] James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In Marilyn Walker, Heng Ji, and Amanda Stent, editors, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 809–819, New Orleans, Louisiana, June 2018. Association for Computational Linguistics.\\n\\n[91] Neema Kotonya and Francesca Toni. Explainable automated fact-checking for public health claims, 2020.\\n\\n[92] Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop?\\n\\na question answering benchmark with implicit reasoning strategies, 2021.\\n\\n[93] Hiroaki Hayashi, Prashant Budania, Peng Wang, Chris Ackerson, Raj Neervannan, and Graham Neubig. Wikiasp:\\n\\nA dataset for multi-domain aspect-based summarization, 2020.\\n\\n[94] Shashi Narayan, Shay B. Cohen, and Mirella Lapata. Don’t give me the details, just the summary! topic-aware\\n\\nconvolutional neural networks for extreme summarization, 2018.\\n\\n[95] Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In David Yarowsky, Timothy Baldwin, Anna Korhonen, Karen Livescu, and Steven Bethard, editors, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631–1642, Seattle, Washington, USA, October 2013. Association for Computational Linguistics.\\n\\n38\\n\\n[96] Sourav Saha, Jahedul Alam Junaed, Maryam Saleki, Arnab Sen Sharma, Mohammad Rashidujjaman Rifat, Mohamed Rahouti, Syed Ishtiaque Ahmed, Nabeel Mohammed, and Mohammad Ruhul Amin. Vio-lens: A novel dataset of annotated social network posts leading to different forms of communal violence and its evaluation. In Firoj Alam, Sudipta Kar, Shammur Absar Chowdhury, Farig Sadeque, and Ruhul Amin, editors, Proceedings of the First Workshop on Bangla Language Processing (BLP-2023), pages 72–84, Singapore, December 2023. Association for Computational Linguistics.\\n\\n[97] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc Brockschmidt. Codesearchnet\\n\\nchallenge: Evaluating the state of semantic code search, 2020.\\n\\n[98] Nandan Thakur, Luiz Bonifacio, Xinyu Zhang, Odunayo Ogundepo, Ehsan Kamalloo, David Alfonso-Hermelo, Xiaoguang Li, Qun Liu, Boxing Chen, Mehdi Rezagholizadeh, and Jimmy Lin. \"knowing when you don’t know\": A multilingual relevance assessment dataset for robust retrieval-augmented generation, 2024.\\n\\n[99] Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture models, 2016. [100] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems, 2021.\\n\\n[101] Ralf Steinberger, Bruno Pouliquen, Anna Widiger, Camelia Ignat, Tomaž Erjavec, Dan Tufi¸s, and Dániel Varga. The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages. In Nicoletta Calzolari, Khalid Choukri, Aldo Gangemi, Bente Maegaard, Joseph Mariani, Jan Odijk, and Daniel Tapias, editors, Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC‘06), Genoa, Italy, May 2006. European Language Resources Association (ELRA).\\n\\n39'),\n",
       " Document(metadata={'source': 'F:\\\\Tapas\\\\Learning\\\\GenAI\\\\data\\\\presentation_on_ai1.pdf'}, page_content='Generative AI: Using Gen AI to Talk About Gen AI\\n\\nRetrieval 09112024: Dall-E-3. Prompt: Create an image that illustrates Generative AI at Harvard University.\" .\\n\\nJohn Graves Associate Director of Academic Technology and Media Services Harvard Chan School\\n\\nEmail: jgraves@hsph.harvard.edu\\n\\nJapanese American\\n\\n• Educator • • Drummer • Curious • A Generative AI enthusiast, but not an expert\\n\\nInstructional Technologist / Instructional Designer\\n\\nRetrieval 09112024,Dall-E-3.Prompt: \"Could you make this picture look like a Hokusai woodblock print? \"\\n\\nWhere we are headed...\\n\\nUsing Gen AI to Talk About Gen AI? (Prompt Engineering) • The Harvard Generative AI Landscape: The Learner Perspective • Next Steps • Open discussion and Q&A\\n\\nRetrieval 09112024, Dall-E-3. Prompt: Create an image that shows Generative AI at a futuristic Harvard University, Could you change the text \"Ivy League University,\" to Harvard University?\"\\n\\nWhat is Generative AI?\\n\\nRetrieval 09112024, Dall-E-3. Prompt: Create an image set in modern Tokyo illustrating what Generative AI is..\"\\n\\nWhat is Generative AI?: Defined with Gen AI\\n\\nHarvard AI Sandbox: https://huit.harvard.edu/ai-sandbox\\n\\nDeveloped a prompt and entered it into the site https://huit.harvard.edu/ai-sandbox .\\n\\no The prompt: What is Generative AI?\\n\\nRefined the definition using additional prompts (Prompt Engineering)\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompt: Created an outline of a PowerPoint presentation on use of Generative AI in Teaching and Learning.\\n\\nHarvard AI Sandbox: https://huit.harvard.edu/ai-sandbox\\n\\nExisting Data • Training\\n\\nPrompt: ChatGPT 4.0 What is Generative AI?\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompts: What is Generative AI? , Could you define Generative AI in two sentences?, Could you make this definition so a wider audience could understand it?\\n\\nPrompt #1: What is Generative AI? Generative AI refers to a subset of artificial intelligence (AI) techniques designed to create new content. This could include text, images, music, or other types of data. These systems leverage sophisticated algorithms and deep learning models to produce outputs that resemble those created by humans. Key technologies behind Generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: Comprising two neural networks — a generator and a discriminator — that compete against each other. The generator tries to produce convincing data instances while the discriminator evaluates them for authenticity. Over time, this adversarial process helps the generator create highly realistic outputs. 2. **Variational Autoencoders (VAEs)**: These combine neural networks with probabilistic approaches to encode and decode data. VAEs are particularly useful for generating new data points that are variations of the input data. 3. **Transformer Models**: Especially prominent in the realm of natural language processing. Models like OpenAI\\'s GPT-3 (Generative Pre-trained Transformer 3) can generate coherent and contextually appropriate text based on input prompts. **Applications of Generative AI:** 1. **Text Generation**: Generating articles, poems, answers to questions, and even computer code. 2. **Image Creation and Editing**: Producing realistic images or transforming existing ones (e.g., turning sketches into detailed pictures). 3. **Music Composition**: Creating new music pieces in various styles. 4. **Synthetic Data Generation**: Producing useful datasets for training machine learning models when real data is scarce or expensive to obtain. 5. **Creative Industries**: Assisting artists, writers, and designers in brainstorming and developing new concepts. Generative AI continues to evolve, pushing the boundaries of what machines can create, and has broad implications across various fields, including entertainment, medicine, and research.\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompts: What is Generative AI? , Could you define Generative AI in two sentences?, Could you make this definition so a wider audience could understand it?\\n\\nPrompt #2: Could you define Generative AI in two sentences?\\n\\nGenerative AI is a subset of artificial intelligence that uses algorithms, particularly neural networks, to create new content such as text, images, or music that mimics human creation. It leverages models like Generative Adversarial Networks (GANs) and Transformer models to generate data that is often indistinguishable from that produced by humans.\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompts: What is Generative AI? , Could you define Generative AI in two sentences?, Could you make this definition so a wider audience could understand it?\\n\\nPrompt #3: Could you make this definition so a wider audience could understand it?\\n\\nGenerative AI is a type of artificial intelligence that creates new content, such as writing stories, drawing pictures, or composing music, similar to what a human might make. It uses advanced computer programs to learn from existing data and produce realistic and creative outputs.\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompts: What is Generative AI? , Could you define Generative AI in two sentences?, Could you make this definition so a wider audience could understand it?\\n\\nThe Presentation Outline Jumpstarted with Gen AI\\n\\nHarvard AI Sandbox: https://huit.harvard.edu/ai-sandbox\\n\\nDeveloped a prompt and entered it into the site https://huit.harvard.edu/ai-sandbox .\\n\\no The prompt: Created an outline of a PowerPoint presentation on use of Generative AI in Teaching and Learning.\\n\\nEntered the outline into the slides.\\n\\nBegan my own research of the generated content to validate it and refine it.\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompt: Created an outline of a PowerPoint presentation on use of Generative AI in Teaching and Learning.\\n\\nPrompt: ChatGPT 4.0 Created an outline of a PowerPoint presentation on use of Generative AI in Teaching and Learning.\\n\\nCertainly! Here\\'s an outline for a PowerPoint presentation on the use of Generative AI in Teaching and Learning: ---\\n\\nSlide 1: Title Slide - Title: The Role of Generative AI in Teaching and Learning - Subtitle: Transforming Education with Advanced AI Technologies - Your Name - • Slide 2: Introduction - Introduction to the concept of AI and Generative AI - Brief Overview of the Presentation Structure • Slide 3: What is Generative AI? - Definition: Generative AI explained - Key Technologies: Machine Learning, Neural Networks, GPT, etc. - Examples: Chat GPT, DALL-E, etc. • Slide 4: Generative AI in Education - How Generative AI is being applied in education - Current trends and applications • Slide 5: Enhancing Teaching with Generative AI - Automating Administrative Tasks: Grading, Attendance, Scheduling - Personalized Learning: Tailored content generation - Tutoring and Mentoring: AI-driven tutoring systems\\n\\nSlide 6: Enhancing Learning with Generative AI - Content Creation: Interactive and immersive content (text, audio, video) - Simulations and Scenario-Based Learning: Virtual labs, Situational simulations - Adaptive Learning Systems: Real-time feedback and adjustments\\n\\nSlide 7: Case Studies - Examples of schools, universities, or educational platforms using Generative AI - Success stories and outcomes • Slide 8: Advantages of Generative AI in Education - Efficiency: Saving time for educators - Personalization: Catering to individual student needs - Engagement: Making learning more interactive and engaging\\n\\nSlide 9: Challenges and Considerations - Ethical Concerns: Bias, Privacy, Data Security - Implementation Barriers: Cost, Infrastructure, Training - Limitations of Current Technologies • Slide 10: Best Practices for Integrating Generative AI - Steps for educators and institutions to implement Generative AI - Collaborations: Partnering with EdTech companies - Continuous Training and Development for Educators\\n\\nSlide 11: Future Trends and Opportunities - Emerging Technologies: Advancements in AI - Long-term Impact on Education: Predictions and possibilities • Slide 12: Q&A - Open Floor for Questions and Discussion • Slide 13: Conclusion - Recap of key points - Closing remarks - Contact Information --- This outline provides a structured approach to discussing the impact and potential of Generative AI in teaching and learning. Feel free to adjust the content according to your audience and presentation goals.\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompt: Created an outline of a PowerPoint presentation on use of Generative AI in Teaching and Learning.\\n\\nThe Harvard Generative AI Landscape: The Learner Perspective\\n\\nRetrieval 09112024: Dall-E-3. Prompt: Create an image that illustrates Generative AI at Harvard University.\" .\\n\\nFall 2023 Survey of 350+ Harvard Students\\n\\n65%\\n\\nof students say they use or plan to use generative AI for academic work.\\n\\nHarvard AI Steering Working Group. \"AI at Harvard Library: Recent Explorations and Future Opportunities.\" Presentation, 03/20/2024.\\n\\nHow students use ChatGPT for academic work\\n\\nTo summarize text of readings • To suggest specific improvements to or edit writing\\n\\nTo do a preliminary search for information & beginning lit reviews\\n\\nAs a learning partner to understand a new topic or concept\\n\\nAs a brainstorming partner • As a language translation tool • For help with coding\\n\\nTo get a quick definition (when the context or source doesn\\'t matter)\\n\\nHarvard AI Steering Working Group. \"AI at Harvard Library: Recent Explorations and Future Opportunities.\" Presentation, 03/20/2024.\\n\\nKey Insight: Use of ChatGPT as a Learning Partner\\n\\n\"I\\'m in a really hard Physics class and I\\'ve been using\\n\\nChatGPT to explain Physics concepts to me. If I don\\'t\\n\\nunderstand something it is helpful to have it described\\n\\nto me in different ways. It can quiz me or debate with\\n\\nme. Sometimes it is more helpful than the way it is\\n\\ndefined in the lecture.\"\\n\\nJunior, History of Science & Global Health\\n\\nHarvard AI Steering Working Group. \"AI at Harvard Library: Recent Explorations and Future Opportunities.\" Presentation, 03/20/2024.\\n\\nKey Insight: Evaluating research impact & importance\\n\\n“I don\\'t think I would use ChatGPT for finding sources\\n\\ndirectly. But if my question was something like tell me\\n\\nabout the five biggest findings in reinforcement learning in\\n\\nthe past decade, I’d use it. It would help me figure out who\\n\\nthe major researchers are in the space and could suggest\\n\\nkeywords for I can\\n\\nuse.\" -Junior, Neuroscience\\n\\nHarvard AI Steering Working Group. \"AI at Harvard Library: Recent Explorations and Future Opportunities.\" Presentation, 03/20/2024.\\n\\nNext Steps?\\n\\nGet a Harvard AI Sandbox account • Start small • Be curious and have fun\\n\\nRetrieval: 09112024 ChatGPT 4.0: Harvard AI Sandbox: Prompts: Create a person at the Harvard TH Chan School of Public Health that is ready to get started with Generative AI.\\n\\nAI Around Harvard and Cambridge\\n\\nAI at Harvard Chan Harvard T.H. Chan School of Public Health https://www.hsph.harvard.edu/information-technology/generative-ai-at-harvard-chan/\\n\\nEmbracing Artificial Intelligence in the Classroom: Harvard Graduate School for Education https://www.gse.harvard.edu/ideas/usable-knowledge/23/07/embracing-artificial-intelligence-classroom\\n\\nArtificial Intelligence at Harvard Kennedy School (HKS) Harvard Kennedy School https://www.hks.harvard.edu/artificial-intelligence\\n\\nGenerative AI in Teaching and Learning: Harvard Office of the VPAL https://www.youtube.com/playlist?list=PL_kRkvxqHjkqjnhAdSdejAkyQf1TnPkNM\\n\\nAI Hub: Generative AI for Teaching and Learning: MIT Sloan https://mitsloanedtech.mit.edu/ai/\\n\\nThank You\\n\\nJohn Graves jgraves@hsph.harvard.edu Associate Director of Academic Technology and Media Services HSPH • • Educator • • Curious • A Generative AI enthusiast, but not an expert\\n\\nJapanese American\\n\\nInstructional Technologist / Instructional Designer\\n\\nRetrieval 09112024,Dall-E-3.Prompt: \"Could you make this picture look like a Hokusai woodblock print? \"'),\n",
       " Document(metadata={'source': 'F:\\\\Tapas\\\\Learning\\\\GenAI\\\\data\\\\state_of_the_union.txt'}, page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.\\n\\nLast year COVID-19 kept us apart. This year we are finally together again.\\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans.\\n\\nWith a duty to one another to the American people to the Constitution.\\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny.\\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated.\\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined.\\n\\nHe met the Ukrainian people.\\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight.\\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world.\\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people.\\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.\\n\\nThey keep moving.\\n\\nAnd the costs and the threats to America and the world keep rising.\\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2.\\n\\nThe United States is a member along with 29 other nations.\\n\\nIt matters. American diplomacy matters. American resolve matters.\\n\\nPutin’s latest attack on Ukraine was premeditated and unprovoked.\\n\\nHe rejected repeated efforts at diplomacy.\\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.\\n\\nWe prepared extensively and carefully.\\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin.\\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.\\n\\nWe countered Russia’s lies with truth.\\n\\nAnd now that he has acted the free world is holding him accountable.\\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland.\\n\\nWe are inflicting pain on Russia and supporting the people of Ukraine. Putin is now isolated from the world more than ever.\\n\\nTogether with our allies –we are right now enforcing powerful economic sanctions.\\n\\nWe are cutting off Russia’s largest banks from the international financial system.\\n\\nPreventing Russia’s central bank from defending the Russian Ruble making Putin’s $630 Billion “war fund” worthless.\\n\\nWe are choking off Russia’s access to technology that will sap its economic strength and weaken its military for years to come.\\n\\nTonight I say to the Russian oligarchs and corrupt leaders who have bilked billions of dollars off this violent regime no more.\\n\\nThe U.S. Department of Justice is assembling a dedicated task force to go after the crimes of Russian oligarchs.\\n\\nWe are joining with our European allies to find and seize your yachts your luxury apartments your private jets. We are coming for your ill-begotten gains.\\n\\nAnd tonight I am announcing that we will join our allies in closing off American air space to all Russian flights – further isolating Russia – and adding an additional squeeze –on their economy. The Ruble has lost 30% of its value.\\n\\nThe Russian stock market has lost 40% of its value and trading remains suspended. Russia’s economy is reeling and Putin alone is to blame.\\n\\nTogether with our allies we are providing support to the Ukrainians in their fight for freedom. Military assistance. Economic assistance. Humanitarian assistance.\\n\\nWe are giving more than $1 Billion in direct assistance to Ukraine.\\n\\nAnd we will continue to aid the Ukrainian people as they defend their country and to help ease their suffering.\\n\\nLet me be clear, our forces are not engaged and will not engage in conflict with Russian forces in Ukraine.\\n\\nOur forces are not going to Europe to fight in Ukraine, but to defend our NATO Allies – in the event that Putin decides to keep moving west.\\n\\nFor that purpose we’ve mobilized American ground forces, air squadrons, and ship deployments to protect NATO countries including Poland, Romania, Latvia, Lithuania, and Estonia.\\n\\nAs I have made crystal clear the United States and our Allies will defend every inch of territory of NATO countries with the full force of our collective power.\\n\\nAnd we remain clear-eyed. The Ukrainians are fighting back with pure courage. But the next few days weeks, months, will be hard on them.\\n\\nPutin has unleashed violence and chaos.  But while he may make gains on the battlefield – he will pay a continuing high price over the long run.\\n\\nAnd a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.\\n\\nTo all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has costs around the world.\\n\\nAnd I’m taking robust action to make sure the pain of our sanctions  is targeted at Russia’s economy. And I will use every tool at our disposal to protect American businesses and consumers.\\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.\\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.\\n\\nThese steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming.\\n\\nBut I want you to know that we are going to be okay.\\n\\nWhen the history of this era is written Putin’s war on Ukraine will have left Russia weaker and the rest of the world stronger.\\n\\nWhile it shouldn’t have taken something so terrible for people around the world to see what’s at stake now everyone sees it clearly.\\n\\nWe see the unity among leaders of nations and a more unified Europe a more unified West. And we see unity among the people who are gathering in cities in large crowds around the world even in Russia to demonstrate their support for Ukraine.\\n\\nIn the battle between democracy and autocracy, democracies are rising to the moment, and the world is clearly choosing the side of peace and security.\\n\\nThis is a real test. It’s going to take time. So let us continue to draw inspiration from the iron will of the Ukrainian people.\\n\\nTo our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you.\\n\\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people.\\n\\nHe will never extinguish their love of freedom. He will never weaken the resolve of the free world.\\n\\nWe meet tonight in an America that has lived through two of the hardest years this nation has ever faced.\\n\\nThe pandemic has been punishing.\\n\\nAnd so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more.\\n\\nI understand.\\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it.\\n\\nThat’s why one of the first things I did as President was fight to pass the American Rescue Plan.\\n\\nBecause people were hurting. We needed to act, and we did.\\n\\nFew pieces of legislation have done more in a critical moment in our history to lift us out of crisis.\\n\\nIt fueled our efforts to vaccinate the nation and combat COVID-19. It delivered immediate economic relief for tens of millions of Americans.\\n\\nHelped put food on their table, keep a roof over their heads, and cut the cost of health insurance.\\n\\nAnd as my Dad used to say, it gave people a little breathing room.\\n\\nAnd unlike the $2 Trillion tax cut passed in the previous administration that benefitted the top 1% of Americans, the American Rescue Plan helped working people—and left no one behind.\\n\\nAnd it worked. It created jobs. Lots of jobs.\\n\\nIn fact—our economy created over 6.5 Million new jobs just last year, more jobs created in one year than ever before in the history of America.\\n\\nOur economy grew at a rate of 5.7% last year, the strongest growth in nearly 40 years, the first step in bringing fundamental change to an economy that hasn’t worked for the working people of this nation for too long.\\n\\nFor the past 40 years we were told that if we gave tax breaks to those at the very top, the benefits would trickle down to everyone else.\\n\\nBut that trickle-down theory led to weaker economic growth, lower wages, bigger deficits, and the widest gap between those at the top and everyone else in nearly a century.\\n\\nVice President Harris and I ran for office with a new economic vision for America.\\n\\nInvest in America. Educate Americans. Grow the workforce. Build the economy from the bottom up and the middle out, not from the top down.\\n\\nBecause we know that when the middle class grows, the poor have a ladder up and the wealthy do very well.\\n\\nAmerica used to have the best roads, bridges, and airports on Earth.\\n\\nNow our infrastructure is ranked 13th in the world.\\n\\nWe won’t be able to compete for the jobs of the 21st Century if we don’t fix that.\\n\\nThat’s why it was so important to pass the Bipartisan Infrastructure Law—the most sweeping investment to rebuild America in history.\\n\\nThis was a bipartisan effort, and I want to thank the members of both parties who worked to make it happen.\\n\\nWe’re done talking about infrastructure weeks.\\n\\nWe’re going to have an infrastructure decade.\\n\\nIt is going to transform America and put us on a path to win the economic competition of the 21st Century that we face with the rest of the world—particularly with China.\\n\\nAs I’ve told Xi Jinping, it is never a good bet to bet against the American people.\\n\\nWe’ll create good jobs for millions of Americans, modernizing roads, airports, ports, and waterways all across America.\\n\\nAnd we’ll do it all to withstand the devastating effects of the climate crisis and promote environmental justice.\\n\\nWe’ll build a national network of 500,000 electric vehicle charging stations, begin to replace poisonous lead pipes—so every child—and every American—has clean water to drink at home and at school, provide affordable high-speed internet for every American—urban, suburban, rural, and tribal communities.\\n\\n4,000 projects have already been announced.\\n\\nAnd tonight, I’m announcing that this year we will start fixing over 65,000 miles of highway and 1,500 bridges in disrepair.\\n\\nWhen we use taxpayer dollars to rebuild America – we are going to Buy American: buy American products to support American jobs.\\n\\nThe federal government spends about $600 Billion a year to keep the country safe and secure.\\n\\nThere’s been a law on the books for almost a century to make sure taxpayers’ dollars support American jobs and businesses.\\n\\nEvery Administration says they’ll do it, but we are actually doing it.\\n\\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America.\\n\\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\\n\\nThat’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing.\\n\\nLet me give you one example of why it’s so important to pass it.\\n\\nIf you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land.\\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built.\\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”.\\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs.\\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives.\\n\\nSmartphones. The Internet. Technology we have yet to invent.\\n\\nBut that’s just the beginning.\\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from $20 billion to $100 billion.\\n\\nThat would be one of the biggest investments in manufacturing in American history.\\n\\nAnd all they’re waiting for is for you to pass this bill.\\n\\nSo let’s not wait any longer. Send it to my desk. I’ll sign it.\\n\\nAnd we will really take off.\\n\\nAnd Intel is not alone.\\n\\nThere’s something happening in America.\\n\\nJust look around and you’ll see an amazing story.\\n\\nThe rebirth of the pride that comes from stamping products “Made In America.” The revitalization of American manufacturing.\\n\\nCompanies are choosing to build new factories here, when just a few years ago, they would have built them overseas.\\n\\nThat’s what is happening. Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country.\\n\\nGM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan.\\n\\nAll told, we created 369,000 new manufacturing jobs in America just last year.\\n\\nPowered by people I’ve met like JoJo Burgess, from generations of union steelworkers from Pittsburgh, who’s here with us tonight.\\n\\nAs Ohio Senator Sherrod Brown says, “It’s time to bury the label “Rust Belt.”\\n\\nIt’s time.\\n\\nBut with all the bright spots in our economy, record job growth and higher wages, too many families are struggling to keep up with the bills.\\n\\nInflation is robbing them of the gains they might otherwise feel.\\n\\nI get it. That’s why my top priority is getting prices under control.\\n\\nLook, our economy roared back faster than most predicted, but the pandemic meant that businesses had a hard time hiring enough workers to keep up production in their factories.\\n\\nThe pandemic also disrupted global supply chains.\\n\\nWhen factories close, it takes longer to make goods and get them from the warehouse to the store, and prices go up.\\n\\nLook at cars.\\n\\nLast year, there weren’t enough semiconductors to make all the cars that people wanted to buy.\\n\\nAnd guess what, prices of automobiles went up.\\n\\nSo—we have a choice.\\n\\nOne way to fight inflation is to drive down wages and make Americans poorer.\\n\\nI have a better plan to fight inflation.\\n\\nLower your costs, not your wages.\\n\\nMake more cars and semiconductors in America.\\n\\nMore infrastructure and innovation in America.\\n\\nMore goods moving faster and cheaper in America.\\n\\nMore jobs where you can earn a good living in America.\\n\\nAnd instead of relying on foreign supply chains, let’s make it in America.\\n\\nEconomists call it “increasing the productive capacity of our economy.”\\n\\nI call it building a better America.\\n\\nMy plan to fight inflation will lower your costs and lower the deficit.\\n\\n17 Nobel laureates in economics say my plan will ease long-term inflationary pressures. Top business leaders and most Americans support my plan. And here’s the plan:\\n\\nFirst – cut the cost of prescription drugs. Just look at insulin. One in ten Americans has diabetes. In Virginia, I met a 13-year-old boy named Joshua Davis.\\n\\nHe and his Dad both have Type 1 diabetes, which means they need insulin every day. Insulin costs about $10 a vial to make.\\n\\nBut drug companies charge families like Joshua and his Dad up to 30 times more. I spoke with Joshua’s mom.\\n\\nImagine what it’s like to look at your child who needs insulin and have no idea how you’re going to pay for it.\\n\\nWhat it does to your dignity, your ability to look your child in the eye, to be the parent you expect to be.\\n\\nJoshua is here with us tonight. Yesterday was his birthday. Happy birthday, buddy.\\n\\nFor Joshua, and for the 200,000 other young people with Type 1 diabetes, let’s cap the cost of insulin at $35 a month so everyone can afford it.\\n\\nDrug companies will still do very well. And while we’re at it let Medicare negotiate lower prices for prescription drugs, like the VA already does.\\n\\nLook, the American Rescue Plan is helping millions of families on Affordable Care Act plans save $2,400 a year on their health care premiums. Let’s close the coverage gap and make those savings permanent.\\n\\nSecond – cut energy costs for families an average of $500 a year by combatting climate change.\\n\\nLet’s provide investments and tax credits to weatherize your homes and businesses to be energy efficient and you get a tax credit; double America’s clean energy production in solar, wind, and so much more;  lower the price of electric vehicles, saving you another $80 a month because you’ll never have to pay at the gas pump again.\\n\\nThird – cut the cost of child care. Many families pay up to $14,000 a year for child care per child.\\n\\nMiddle-class and working families shouldn’t have to pay more than 7% of their income for care of young children.\\n\\nMy plan will cut the cost in half for most families and help parents, including millions of women, who left the workforce during the pandemic because they couldn’t afford child care, to be able to get back to work.\\n\\nMy plan doesn’t stop there. It also includes home and long-term care. More affordable housing. And Pre-K for every 3- and 4-year-old.\\n\\nAll of these will lower costs.\\n\\nAnd under my plan, nobody earning less than $400,000 a year will pay an additional penny in new taxes. Nobody.\\n\\nThe one thing all Americans agree on is that the tax system is not fair. We have to fix it.\\n\\nI’m not looking to punish anyone. But let’s make sure corporations and the wealthiest Americans start paying their fair share.\\n\\nJust last year, 55 Fortune 500 corporations earned $40 billion in profits and paid zero dollars in federal income tax.\\n\\nThat’s simply not fair. That’s why I’ve proposed a 15% minimum tax rate for corporations.\\n\\nWe got more than 130 countries to agree on a global minimum tax rate so companies can’t get out of paying their taxes at home by shipping jobs and factories overseas.\\n\\nThat’s why I’ve proposed closing loopholes so the very wealthy don’t pay a lower tax rate than a teacher or a firefighter.\\n\\nSo that’s my plan. It will grow the economy and lower costs for families.\\n\\nSo what are we waiting for? Let’s get this done. And while you’re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.\\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit.\\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted.\\n\\nBut in my administration, the watchdogs have been welcomed back.\\n\\nWe’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.\\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud.\\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.\\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year.\\n\\nLowering your costs also means demanding more competition.\\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism.\\n\\nIt’s exploitation—and it drives up prices.\\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under.\\n\\nWe see it happening with ocean carriers moving goods in and out of America.\\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits.\\n\\nTonight, I’m announcing a crackdown on these companies overcharging American businesses and consumers.\\n\\nAnd as Wall Street firms take over more nursing homes, quality in those homes has gone down and costs have gone up.\\n\\nThat ends on my watch.\\n\\nMedicare is going to set higher standards for nursing homes and make sure your loved ones get the care they deserve and expect.\\n\\nWe’ll also cut costs and keep the economy going strong by giving workers a fair shot, provide more training and apprenticeships, hire them based on their skills not degrees.\\n\\nLet’s pass the Paycheck Fairness Act and paid leave.\\n\\nRaise the minimum wage to $15 an hour and extend the Child Tax Credit, so no one has to raise a family in poverty.\\n\\nLet’s increase Pell Grants and increase our historic support of HBCUs, and invest in what Jill—our First Lady who teaches full-time—calls America’s best-kept secret: community colleges.\\n\\nAnd let’s pass the PRO Act when a majority of workers want to form a union—they shouldn’t be stopped.\\n\\nWhen we invest in our workers, when we build the economy from the bottom up and the middle out together, we can do something we haven’t done in a long time: build a better America.\\n\\nFor more than two years, COVID-19 has impacted every decision in our lives and the life of the nation.\\n\\nAnd I know you’re tired, frustrated, and exhausted.\\n\\nBut I also know this.\\n\\nBecause of the progress we’ve made, because of your resilience and the tools we have, tonight I can say we are moving forward safely, back to more normal routines.\\n\\nWe’ve reached a new moment in the fight against COVID-19, with severe cases down to a level not seen since last July.\\n\\nJust a few days ago, the Centers for Disease Control and Prevention—the CDC—issued new mask guidelines.\\n\\nUnder these new guidelines, most Americans in most of the country can now be mask free.\\n\\nAnd based on the projections, more of the country will reach that point across the next couple of weeks.\\n\\nThanks to the progress we have made this past year, COVID-19 need no longer control our lives.\\n\\nI know some are talking about “living with COVID-19”. Tonight – I say that we will never just accept living with COVID-19.\\n\\nWe will continue to combat the virus as we do other diseases. And because this is a virus that mutates and spreads, we will stay on guard.\\n\\nHere are four common sense steps as we move forward safely.\\n\\nFirst, stay protected with vaccines and treatments. We know how incredibly effective vaccines are. If you’re vaccinated and boosted you have the highest degree of protection.\\n\\nWe will never give up on vaccinating more Americans. Now, I know parents with kids under 5 are eager to see a vaccine authorized for their children.\\n\\nThe scientists are working hard to get that done and we’ll be ready with plenty of vaccines when they do.\\n\\nWe’re also ready with anti-viral treatments. If you get COVID-19, the Pfizer pill reduces your chances of ending up in the hospital by 90%.\\n\\nWe’ve ordered more of these pills than anyone in the world. And Pfizer is working overtime to get us 1 Million pills this month and more than double that next month.\\n\\nAnd we’re launching the “Test to Treat” initiative so people can get tested at a pharmacy, and if they’re positive, receive antiviral pills on the spot at no cost.\\n\\nIf you’re immunocompromised or have some other vulnerability, we have treatments and free high-quality masks.\\n\\nWe’re leaving no one behind or ignoring anyone’s needs as we move forward.\\n\\nAnd on testing, we have made hundreds of millions of tests available for you to order for free.\\n\\nEven if you already ordered free tests tonight, I am announcing that you can order more from covidtests.gov starting next week.\\n\\nSecond – we must prepare for new variants. Over the past year, we’ve gotten much better at detecting new variants.\\n\\nIf necessary, we’ll be able to deploy new vaccines within 100 days instead of many more months or years.\\n\\nAnd, if Congress provides the funds we need, we’ll have new stockpiles of tests, masks, and pills ready if needed.\\n\\nI cannot promise a new variant won’t come. But I can promise you we’ll do everything within our power to be ready if it does.\\n\\nThird – we can end the shutdown of schools and businesses. We have the tools we need.\\n\\nIt’s time for Americans to get back to work and fill our great downtowns again.  People working from home can feel safe to begin to return to the office.\\n\\nWe’re doing that here in the federal government. The vast majority of federal workers will once again work in person.\\n\\nOur schools are open. Let’s keep it that way. Our kids need to be in school.\\n\\nAnd with 75% of adult Americans fully vaccinated and hospitalizations down by 77%, most Americans can remove their masks, return to work, stay in the classroom, and move forward safely.\\n\\nWe achieved this because we provided free vaccines, treatments, tests, and masks.\\n\\nOf course, continuing this costs money.\\n\\nI will soon send Congress a request.\\n\\nThe vast majority of Americans have used these tools and may want to again, so I expect Congress to pass it quickly.\\n\\nFourth, we will continue vaccinating the world.\\n\\nWe’ve sent 475 Million vaccine doses to 112 countries, more than any other nation.\\n\\nAnd we won’t stop.\\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life.\\n\\nLet’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.\\n\\nLet’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.\\n\\nWe can’t change how divided we’ve been. But we can change how we move forward—on COVID-19 and other issues we must face together.\\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera.\\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.\\n\\nOfficer Mora was 27 years old.\\n\\nOfficer Rivera was 22.\\n\\nBoth Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers.\\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\n\\nI’ve worked on these issues a long time.\\n\\nI know what works: Investing in crime prevention and community police officers who’ll walk the beat, who’ll know the neighborhood, and who can restore trust and safety.\\n\\nSo let’s not abandon our streets. Or choose between safety and equal justice.\\n\\nLet’s come together to protect our communities, restore trust, and hold law enforcement accountable.\\n\\nThat’s why the Justice Department required body cameras, banned chokeholds, and restricted no-knock warrants for its officers.\\n\\nThat’s why the American Rescue Plan provided $350 Billion that cities, states, and counties can use to hire more police and invest in proven strategies like community violence interruption—trusted messengers breaking the cycle of violence and trauma and giving young people hope.\\n\\nWe should all agree: The answer is not to Defund the police. The answer is to FUND the police with the resources and training they need to protect our communities.\\n\\nI ask Democrats and Republicans alike: Pass my budget and keep our neighborhoods safe.\\n\\nAnd I will keep doing everything in my power to crack down on gun trafficking and ghost guns you can buy online and make at home—they have no serial numbers and can’t be traced.\\n\\nAnd I ask Congress to pass proven measures to reduce gun violence. Pass universal background checks. Why should anyone on a terrorist list be able to purchase a weapon?\\n\\nBan assault weapons and high-capacity magazines.\\n\\nRepeal the liability shield that makes gun manufacturers the only industry in America that can’t be sued.\\n\\nThese laws don’t infringe on the Second Amendment. They save lives.\\n\\nThe most fundamental right in America is the right to vote – and to have it counted. And it’s under assault.\\n\\nIn state after state, new laws have been passed, not only to suppress the vote, but to subvert entire elections.\\n\\nWe cannot let this happen.\\n\\nTonight. I call on the Senate to: Pass the Freedom to Vote Act. Pass the John Lewis Voting Rights Act. And while you’re at it, pass the Disclose Act so Americans can know who is funding our elections.\\n\\nTonight, I’d like to honor someone who has dedicated his life to serve this country: Justice Stephen Breyer—an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. Justice Breyer, thank you for your service.\\n\\nOne of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court.\\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nation’s top legal minds, who will continue Justice Breyer’s legacy of excellence.\\n\\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since she’s been nominated, she’s received a broad range of support—from the Fraternal Order of Police to former judges appointed by Democrats and Republicans.\\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system.\\n\\nWe can do both. At our border, we’ve installed new technology like cutting-edge scanners to better detect drug smuggling.\\n\\nWe’ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.\\n\\nWe’re putting in place dedicated immigration judges so families fleeing persecution and violence can have their cases heard faster.\\n\\nWe’re securing commitments and supporting partners in South and Central America to host more refugees and secure their own borders.\\n\\nWe can do all this while keeping lit the torch of liberty that has led generations of immigrants to this land—my forefathers and so many of yours.\\n\\nProvide a pathway to citizenship for Dreamers, those on temporary status, farm workers, and essential workers.\\n\\nRevise our laws so businesses have the workers they need and families don’t wait decades to reunite.\\n\\nIt’s not only the right thing to do—it’s the economically smart thing to do.\\n\\nThat’s why immigration reform is supported by everyone from labor unions to religious leaders to the U.S. Chamber of Commerce.\\n\\nLet’s get it done once and for all.\\n\\nAdvancing liberty and justice also requires protecting the rights of women.\\n\\nThe constitutional right affirmed in Roe v. Wade—standing precedent for half a century—is under attack as never before.\\n\\nIf we want to go forward—not backward—we must protect access to health care. Preserve a woman’s right to choose. And let’s continue to advance maternal health care in America.\\n\\nAnd for our LGBTQ+ Americans, let’s finally get the bipartisan Equality Act to my desk. The onslaught of state laws targeting transgender Americans and their families is wrong.\\n\\nAs I said last year, especially to our younger transgender Americans, I will always have your back as your President, so you can be yourself and reach your God-given potential.\\n\\nWhile it often appears that we never agree, that isn’t true. I signed 80 bipartisan bills into law last year. From preventing government shutdowns to protecting Asian-Americans from still-too-common hate crimes to reforming military justice.\\n\\nAnd soon, we’ll strengthen the Violence Against Women Act that I first wrote three decades ago. It is important for us to show the nation that we can come together and do big things.\\n\\nSo tonight I’m offering a Unity Agenda for the Nation. Four big things we can do together.\\n\\nFirst, beat the opioid epidemic.\\n\\nThere is so much we can do. Increase funding for prevention, treatment, harm reduction, and recovery.\\n\\nGet rid of outdated rules that stop doctors from prescribing treatments. And stop the flow of illicit drugs by working with state and local law enforcement to go after traffickers.\\n\\nIf you’re suffering from addiction, know you are not alone. I believe in recovery, and I celebrate the 23 million Americans in recovery.\\n\\nSecond, let’s take on mental health. Especially among our children, whose lives and education have been turned upside down.\\n\\nThe American Rescue Plan gave schools money to hire teachers and help students make up for lost learning.\\n\\nI urge every parent to make sure your school does just that. And we can all play a part—sign up to be a tutor or a mentor.\\n\\nChildren were also struggling before the pandemic. Bullying, violence, trauma, and the harms of social media.\\n\\nAs Frances Haugen, who is here with us tonight, has shown, we must hold social media platforms accountable for the national experiment they’re conducting on our children for profit.\\n\\nIt’s time to strengthen privacy protections, ban targeted advertising to children, demand tech companies stop collecting personal data on our children.\\n\\nAnd let’s get all Americans the mental health services they need. More people they can turn to for help, and full parity between physical and mental health care.\\n\\nThird, support our veterans.\\n\\nVeterans are the best of us.\\n\\nI’ve always believed that we have a sacred obligation to equip all those we send to war and care for them and their families when they come home.\\n\\nMy administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.\\n\\nOur troops in Iraq and Afghanistan faced many dangers.\\n\\nOne was stationed at bases and breathing in toxic smoke from “burn pits” that incinerated wastes of war—medical and hazard material, jet fuel, and more.\\n\\nWhen they came home, many of the world’s fittest and best trained warriors were never the same.\\n\\nHeadaches. Numbness. Dizziness.\\n\\nA cancer that would put them in a flag-draped coffin.\\n\\nI know.\\n\\nOne of those soldiers was my son Major Beau Biden.\\n\\nWe don’t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops.\\n\\nBut I’m committed to finding out everything we can.\\n\\nCommitted to military families like Danielle Robinson from Ohio.\\n\\nThe widow of Sergeant First Class Heath Robinson.\\n\\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq.\\n\\nStationed near Baghdad, just yards from burn pits the size of football fields.\\n\\nHeath’s widow Danielle is here with us tonight. They loved going to Ohio State football games. He loved building Legos with their daughter.\\n\\nBut cancer from prolonged exposure to burn pits ravaged Heath’s lungs and body.\\n\\nDanielle says Heath was a fighter to the very end.\\n\\nHe didn’t know how to stop fighting, and neither did she.\\n\\nThrough her pain she found purpose to demand we do better.\\n\\nTonight, Danielle—we are.\\n\\nThe VA is pioneering new ways of linking toxic exposures to diseases, already helping more veterans get benefits.\\n\\nAnd tonight, I’m announcing we’re expanding eligibility to veterans suffering from nine respiratory cancers.\\n\\nI’m also calling on Congress: pass a law to make sure veterans devastated by toxic exposures in Iraq and Afghanistan finally get the benefits and comprehensive health care they deserve.\\n\\nAnd fourth, let’s end cancer as we know it.\\n\\nThis is personal to me and Jill, to Kamala, and to so many of you.\\n\\nCancer is the #2 cause of death in America–second only to heart disease.\\n\\nLast month, I announced our plan to supercharge the Cancer Moonshot that President Obama asked me to lead six years ago.\\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.\\n\\nMore support for patients and families.\\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.\\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.\\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more.\\n\\nA unity agenda for the nation.\\n\\nWe can do this.\\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy.\\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things.\\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror.\\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known.\\n\\nNow is the hour.\\n\\nOur moment of responsibility.\\n\\nOur test of resolve and conscience, of history itself.\\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged.\\n\\nWell I know this nation.\\n\\nWe will meet the test.\\n\\nTo protect freedom and liberty, to expand fairness and opportunity.\\n\\nWe will save democracy.\\n\\nAs hard as these times have been, I am more optimistic about America today than I have been my whole life.\\n\\nBecause I see the future that is within our grasp.\\n\\nBecause I know there is simply nothing beyond our capacity.\\n\\nWe are the only nation on Earth that has always turned every crisis we have faced into an opportunity.\\n\\nThe only nation that can be defined by a single word: possibilities.\\n\\nSo on this night, in our 245th year as a nation, I have come to report on the State of the Union.\\n\\nAnd my report is this: the State of the Union is strong—because you, the American people, are strong.\\n\\nWe are stronger today than we were a year ago.\\n\\nAnd we will be stronger a year from now than we are today.\\n\\nNow is our moment to meet and overcome the challenges of our time.\\n\\nAnd we will, as one people.\\n\\nOne America.\\n\\nThe United States of America.\\n\\nMay God bless you all. May God protect our troops.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ed53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=spliter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056360ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e9525e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GOOGLE_API_KEY\")\n",
    "embeddings=OpenAIEmbeddings()\n",
    "\n",
    "len(embeddings.embed_query(\"hello how are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f285454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASTRA_DB_API_ENDPOINT=\"load from env\"\n",
    "ASTRA_DB_APPLICATION_TOKEN=\"load from env file\"\n",
    "ASTRA_DB_KEYSPACE=\"load from env file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bae820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_astradb import AstraDBVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66cd4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=AstraDBVectorStore(\n",
    "    collection_name=\"multidoc_vector\",\n",
    "    embedding=embeddings,\n",
    "    api_endpoint=ASTRA_DB_API_ENDPOINT,\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    "    namespace=ASTRA_DB_KEYSPACE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9eb02e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inserted_ids=vector_store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02fbb762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 387 records\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inserted {len(inserted_ids)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d95898",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c250045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['AstraDBVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_astradb.vectorstores.AstraDBVectorStore object at 0x00000255D8D78290>, search_kwargs={'k': 5})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3add8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template=\"\"\"\n",
    "You are an AI philosopher drawing insights from the roadmap of the data. craft a thoughtful \n",
    "response based on the provided insights. your response should be consise and strictly\n",
    "related to the provided context and user query.\n",
    "\n",
    "If the context does not cosist any valid response then say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "Your Response:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29c8653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99c6f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70683ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0b5b26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain= (\n",
    "    {\"context\" : retriever , \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e5c8e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Modular RAG is the latest evolution in RAG paradigms, emphasizing flexibility and customization. It decomposes the retrieval and generation pipeline into independent, reusable components, enabling domain-specific optimization and task adaptability, making it ideal for complex, multi-domain tasks requiring scalability and precision.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What is Modular RAG?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a8e19759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The United States stands with the Ukrainian people, condemning Russia's unprovoked aggression and believing that dictators must pay a price for their actions to prevent further chaos. While US forces will not engage directly in conflict with Russian forces in Ukraine, the US, as a NATO member, will defend every inch of NATO territory with its full collective power, mobilizing forces to protect allies. American diplomacy and resolve are committed to imposing a continuing high price on Russia over the long run.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is the USA stand on Ukraine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc7de2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative AI is a subset of artificial intelligence designed to create new content, such as text, images, or music. It leverages sophisticated algorithms and deep learning models, including neural networks, to produce outputs that resemble those created by humans by learning from existing data.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is Generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce0831",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
