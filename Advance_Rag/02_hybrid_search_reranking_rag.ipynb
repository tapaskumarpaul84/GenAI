{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7722dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all ok\n"
     ]
    }
   ],
   "source": [
    "print(\"all ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4439f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from weaviate.classes.init import Auth\n",
    "load_dotenv()\n",
    "WEAVIATE_KEY=os.getenv(\"WEAVIATE_API_KEY\")\n",
    "WEAVIATE_URL=os.getenv(\"WEAVIATE_URL\")\n",
    "\n",
    "HF_TOKEN=os.getenv(\"HF_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c953d530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i89dhha7t7wg488bixluya.c0.asia-southeast1.gcp.weaviate.cloud'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEAVIATE_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22781281",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"X-HuggingFace-Api-Key\": HF_TOKEN,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cafa991",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url=WEAVIATE_URL,                       # `weaviate_url`: your Weaviate URL\n",
    "    auth_credentials=Auth.api_key(WEAVIATE_KEY),      # `weaviate_key`: your Weaviate API key\n",
    "    headers=headers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0d7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db45bac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.is_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b49546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x1fd11483410>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections.get('hybrid-search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e9ec9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2599e36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x1fd11373f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections.create(\n",
    "    \"HybridCollection\",\n",
    "    vector_config=[\n",
    "        Configure.Vectors.text2vec_huggingface(\n",
    "            name=\"title_vector\",\n",
    "            source_properties=[\"title\"],\n",
    "            # NOTE: Use only one of (`model`), (`passage_model` and `query_model`), or (`endpoint_url`)\n",
    "            model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            # passage_model=\"sentence-transformers/facebook-dpr-ctx_encoder-single-nq-base\",    # Required if using `query_model`\n",
    "            # query_model=\"sentence-transformers/facebook-dpr-question_encoder-single-nq-base\", # Required if using `passage_model`\n",
    "            # endpoint_url=\"<custom_huggingface_url>\",\n",
    "            #\n",
    "            # wait_for_model=True,\n",
    "            # use_cache=True,\n",
    "            # use_gpu=True,\n",
    "        )\n",
    "    ],\n",
    "    # Additional parameters not shown\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc47ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_objects = [\n",
    "    {\"title\": \"The Shawshank Redemption\", \"description\": \"A wrongfully imprisoned man forms an inspiring friendship while finding hope and redemption in the darkest of places.\"},\n",
    "    {\"title\": \"The Godfather\", \"description\": \"A powerful mafia family struggles to balance loyalty, power, and betrayal in this iconic crime saga.\"},\n",
    "    {\"title\": \"The Dark Knight\", \"description\": \"Batman faces his greatest challenge as he battles the chaos unleashed by the Joker in Gotham City.\"},\n",
    "    {\"title\": \"Jingle All the Way\", \"description\": \"A desperate father goes to hilarious lengths to secure the season's hottest toy for his son on Christmas Eve.\"},\n",
    "    {\"title\": \"A Christmas Carol\", \"description\": \"A miserly old man is transformed after being visited by three ghosts on Christmas Eve in this timeless tale of redemption.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9d602f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.use(\"HybridCollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5b9226",
   "metadata": {},
   "outputs": [],
   "source": [
    "with collection.batch.fixed_size(batch_size=200) as batch:\n",
    "    for src_obj in source_objects:\n",
    "        # The model provider integration will automatically vectorize the object\n",
    "        batch.add_object(\n",
    "            properties={\n",
    "                \"title\": src_obj[\"title\"],\n",
    "                \"description\": src_obj[\"description\"],\n",
    "            },\n",
    "            # vector=vector  # Optionally provide a pre-obtained vector\n",
    "        )\n",
    "        if batch.number_errors > 10:\n",
    "            print(\"Batch import stopped due to excessive errors.\")\n",
    "            break\n",
    "\n",
    "failed_objects = collection.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "    print(f\"First failed object: {failed_objects[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80d22d",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eda7c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QueryReturn(objects=[Object(uuid=_WeaviateUUIDInt('48cda31a-841c-4f36-b50f-99c45cf56f4f'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'title': 'A Christmas Carol', 'description': 'A miserly old man is transformed after being visited by three ghosts on Christmas Eve in this timeless tale of redemption.'}, references=None, vector={}, collection='HybridCollection'), Object(uuid=_WeaviateUUIDInt('f44f1ef5-3bdd-4093-81d5-bcce8dfa9ec4'), metadata=MetadataReturn(creation_time=None, last_update_time=None, distance=None, certainty=None, score=None, explain_score=None, is_consistent=None, rerank_score=None), properties={'title': 'The Shawshank Redemption', 'description': 'A wrongfully imprisoned man forms an inspiring friendship while finding hope and redemption in the darkest of places.'}, references=None, vector={}, collection='HybridCollection')])\n"
     ]
    }
   ],
   "source": [
    "collection = client.collections.use(\"HybridCollection\")\n",
    "\n",
    "response = collection.query.near_text(\n",
    "    query=\"A holiday film\",  # The model provider integration will automatically vectorize the query\n",
    "    limit=2\n",
    ")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7829e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Christmas Carol\n",
      "The Shawshank Redemption\n"
     ]
    }
   ],
   "source": [
    "for obj in response.objects:\n",
    "    print(obj.properties[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5f92d",
   "metadata": {},
   "source": [
    "#### Hybrid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec9c75a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Christmas Carol\n",
      "The Shawshank Redemption\n"
     ]
    }
   ],
   "source": [
    "response = collection.query.hybrid(\n",
    "    query=\"A holiday film\",  # The model provider integration will automatically vectorize the query\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(obj.properties[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6af1d",
   "metadata": {},
   "source": [
    "#### Working on pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd8c8072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader=PyPDFLoader(r'F:\\Tapas\\Learning\\GenAI\\resource\\research_paper\\2401.15884v3.pdf')\n",
    "data=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64c556f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50)\n",
    "\n",
    "docs=splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10aeafe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4545db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2024-10-08T01:19:39+00:00', 'author': '', 'keywords': '', 'moddate': '2024-10-08T01:19:39+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'F:\\\\Tapas\\\\Learning\\\\GenAI\\\\resource\\\\research_paper\\\\2401.15884v3.pdf', 'total_pages': 16, 'page': 0, 'page_label': '1'}, page_content='Corrective Retrieval Augmented Generation\\nShi-Qi Yan1*, Jia-Chen Gu2*, Yun Zhu3, Zhen-Hua Ling1\\n1National Engineering Research Center of Speech and Language Information Processing,\\nUniversity of Science and Technology of China, Hefei, China\\n2Department of Computer Science, University of California, Los Angeles\\n3Google DeepMind\\nyansiki@mail.ustc.edu.cn, gujc@ucla.edu, yunzhu@google.com, zhling@ustc.edu.cn\\nAbstract\\nLarge language models (LLMs) inevitably')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "392ef696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.collections.collection.sync.Collection at 0x1fd1a54bad0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.collections.create(\n",
    "    \"HybridCollection\",\n",
    "    vector_config=[\n",
    "        Configure.Vectors.text2vec_huggingface(\n",
    "            name=\"content_vector\",\n",
    "            source_properties=[\"page_content\"],\n",
    "            # NOTE: Use only one of (`model`), (`passage_model` and `query_model`), or (`endpoint_url`)\n",
    "            model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            # passage_model=\"sentence-transformers/facebook-dpr-ctx_encoder-single-nq-base\",    # Required if using `query_model`\n",
    "            # query_model=\"sentence-transformers/facebook-dpr-question_encoder-single-nq-base\", # Required if using `passage_model`\n",
    "            # endpoint_url=\"<custom_huggingface_url>\",\n",
    "            #\n",
    "            # wait_for_model=True,\n",
    "            # use_cache=True,\n",
    "            # use_gpu=True,\n",
    "        )\n",
    "    ],\n",
    "    # Additional parameters not shown\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d700ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.collections.use(\"HybridCollection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34d82388",
   "metadata": {},
   "outputs": [],
   "source": [
    "with collection.batch.fixed_size(batch_size=200) as batch:\n",
    "    for src_obj in docs:\n",
    "        # The model provider integration will automatically vectorize the object\n",
    "        batch.add_object(\n",
    "            properties={\n",
    "                \n",
    "                \"conetnt\": src_obj.page_content,\n",
    "            },\n",
    "            # vector=vector  # Optionally provide a pre-obtained vector\n",
    "        )\n",
    "        if batch.number_errors > 10:\n",
    "            print(\"Batch import stopped due to excessive errors.\")\n",
    "            break\n",
    "\n",
    "failed_objects = collection.batch.failed_objects\n",
    "if failed_objects:\n",
    "    print(f\"Number of failed imports: {len(failed_objects)}\")\n",
    "    print(f\"First failed object: {failed_objects[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8f15e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and Noah Fiedel. 2023. Palm: Scaling language\n",
      "modeling with pathways. J. Mach. Learn. Res. ,\n",
      "24:240:1–240:113.\n",
      "Shehzaad Dhuliawala, Mojtaba Komeili, Jing Xu,\n",
      "Roberta Raileanu, Xian Li, Asli Celikyilmaz, and\n",
      "Jason Weston. 2024. Chain-of-verification reduces\n",
      "hallucination in large language models. pages 3563–\n",
      "3578.\n",
      "Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang,\n",
      "Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, Percy\n",
      "Liang, and Tatsunori B. Hashimoto. 2023. Alpaca-\n",
      "inference. The label of positive samples was 1,\n",
      "while that of negative ones was -1. At inference,\n",
      "the evaluator scored the relevance from -1 to 1 for\n",
      "each document. The two confidence thresholds\n",
      "for triggering one of the three actions were set\n",
      "empirically. Specifically, they were set as (0.59,\n",
      "-0.99) in PopQA, (0.5, -0.91) in PubQA and Arc-\n",
      "Challenge, as well as (0.95, -0.91) in Biography.\n",
      "Internal Knowledge: To obtain fine-grained\n",
      "retrieval results, we segmented the retrieved results\n"
     ]
    }
   ],
   "source": [
    "response = collection.query.near_text(\n",
    "    query=\"what is rag\",  # The model provider integration will automatically vectorize the query\n",
    "    limit=2\n",
    ")\n",
    "#print(response)\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(obj.properties[\"conetnt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3f1c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "play approach can be utilized in other concurrent\n",
      "studies, we specifically designed to insert our\n",
      "CRAG into the Self-RAG (Asai et al., 2024)\n",
      "framework and named it Self-CRAG. Self-RAG\n",
      "et al., 2020) pre-trained model. The dataset we\n",
      "used is the version provided by Self-RAG (Asai\n",
      "et al., 2024). Specifically, the original PopQA\n",
      "dataset consists of 14k samples, 1,399 of which\n",
      "were used for testing following Self-RAG (Asai\n",
      "et al., 2024), and the remaining were used for\n",
      "fine-tuning to avoid information leakage. Besides,\n",
      "the fine-tuned evaluator was transferred and also\n",
      "utilized on the Bio, Pub and ARC datasets during\n",
      "inference. The label of positive samples was 1,\n"
     ]
    }
   ],
   "source": [
    "response = collection.query.hybrid(\n",
    "    query=\"What is RAG?\",  # The model provider integration will automatically vectorize the query\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for obj in response.objects:\n",
    "    print(obj.properties[\"conetnt\"],sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf701f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509346c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2d7163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
